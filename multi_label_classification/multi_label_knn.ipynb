{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.validation import _check_large_sparse\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, jaccard_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_df(item_lists, unique_items):\n",
    "# Create empty dict\n",
    "    bool_dict = {}\n",
    "    \n",
    "    # Loop through all the tags\n",
    "    for i, item in enumerate(unique_items):\n",
    "        \n",
    "        # Apply boolean mask\n",
    "        bool_dict[item] = item_lists.apply(lambda x: 1 if item in x else 0)\n",
    "            \n",
    "    # Return the results as a dataframe\n",
    "    return pd.DataFrame(bool_dict)\n",
    "\n",
    "def to_1D(series):\n",
    "    return pd.Series([x for _list in series for x in _list])"
   ]
  },
  {
   "source": [
    "Edit the cell below to load another dataset or combine them together."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading NA data\n",
    "X_df = pd.read_csv('../new_data/Persian/persian_dataset.csv', index_col=None)\n",
    "Y_df = pd.read_csv('../new_data/Persian/p_labels_cleaned.csv', usecols=['filename', 'emotions'], index_col='filename')\n",
    "# Reading Persian data\n",
    "# X_df_p = pd.read_csv('../new_data/Persian/persian_dataset.csv', index_col=None)\n",
    "# Y_df_p = pd.read_csv('../new_data/Persian/p_labels_cleaned.csv', usecols=['filename', 'emotions'], index_col='filename')\n",
    "\n",
    "# concatenate them\n",
    "# Y_df = pd.concat([Y_df_na, Y_df_p], sort=False)\n",
    "# X_df = pd.concat([X_df_na, X_df_p], ignore_index=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove videos that we deleted from labels.\n",
    "X_df = X_df[X_df['filename'].isin(Y_df.index)]\n",
    "# Reset index to prevent future errors in using iloc\n",
    "X_df.reset_index(inplace=True, drop=True)\n",
    "# Change emotion column to list type\n",
    "Y_df[\"emotions\"] = Y_df[\"emotions\"].apply(eval)\n",
    "\n",
    "label_cols = to_1D(Y_df[\"emotions\"]).unique() \n",
    "labels_expanded = boolean_df(Y_df['emotions'], label_cols )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df['none']  = np.NaN\n",
    "X_df['furious']  = np.NaN\n",
    "X_df['anger']  = np.NaN\n",
    "X_df['annoyed']  = np.NaN\n",
    "X_df['contempt']  = np.NaN\n",
    "X_df['hatred']  = np.NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in X_df.iterrows():\n",
    "    # print(index, row)\n",
    "    filename = X_df.iloc[index]['filename']\n",
    "    # print(labels_expanded.loc[filename]['none':'hatred'].to_list())\n",
    "    X_df.at[index,'none'] = labels_expanded.at[filename,'none']\n",
    "    X_df.at[index,'furious'] = labels_expanded.at[filename,'furious']\n",
    "    X_df.at[index,'anger'] = labels_expanded.at[filename,'anger']\n",
    "    X_df.at[index,'annoyed'] = labels_expanded.at[filename,'annoyed']\n",
    "    X_df.at[index,'contempt'] = labels_expanded.at[filename,'contempt']\n",
    "    X_df.at[index,'hatred'] = labels_expanded.at[filename,'hatred']"
   ]
  },
  {
   "source": [
    "## Ablation Studies\n",
    "Run the cell below to remove columns for ablation studies and then run the training cell."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ratio:  0.13832948167712117\n"
     ]
    }
   ],
   "source": [
    "label_cols = ['none', 'furious', 'anger', 'annoyed', 'contempt', 'hatred']\n",
    "frames = X_df[X_df['none'] == 1].shape[0]\n",
    "print(\"Ratio: \", frames/X_df.shape[0])\n",
    "label_ratio = {'anger': 0.50, 'contempt':0.30, 'hatred': 0.30, 'annoyed': 0.30, 'furious': 0.35, 'none':0.30} # For NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ablation cols\n",
    "# ablation_cols = ['AU01_r','AU02_r','AU04_r','AU05_r','AU06_r','AU07_r','AU09_r', 'AU10_r','AU12_r','AU14_r','AU15_r','AU17_r','AU20_r','AU23_r','AU25_r','AU26_r','AU45_r']\n",
    "ablation_cols = ['pose_Rx','pose_Ry','pose_Rz','gaze_angle_x','gaze_angle_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = X_df.drop(columns=ablation_cols)\n",
    "X_df"
   ]
  },
  {
   "source": [
    "### Min-Max Scaling\n",
    "To limit the scale of features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = list (\n",
    "    set(X_df.columns.to_list()) - set(['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success', 'none', 'furious', 'anger', 'annoyed', 'contempt', 'disgust', 'hatred'])\n",
    ")\n",
    "scaler = MinMaxScaler()\n",
    "X_df[cols_to_scale] = scaler.fit_transform(X_df[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting into train and test\n",
    "Randomly select 25% of videos apart for testing."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = X_df['filename'].unique()\n",
    "# Comment this line and uncomment next to test on Persian videos\n",
    "# test_videos = ['na/vid_13.mp4', 'na/vid_92.mp4', 'na/vid_93.mp4', 'na/vid_6.mp4', 'na/vid_14.mp4', 'na/vid_10_1.mp4', 'na/vid_34.mp4', 'na/vid_86.mp4', 'na/vid_83.mp4', 'na/vid_90.mp4', 'na/vid_60.mp4', 'na/vid_24.mp4', 'na/vid_10_3.mp4', 'na/vid_10_2.mp4', 'na/vid_87.mp4', 'na/vid_32.mp4', 'na/vid_79.mp4', 'na/vid_68.mp4', 'na/vid_56.mp4', 'na/vid_36.mp4']\n",
    "# test_videos = ['persian/vid_59.mp4', 'persian/vid_79.mp4', 'persian/vid_40.mp4', 'persian/vid_10.mp4', 'persian/vid_1.mp4', 'persian/vid_5.mp4', 'persian/vid_44.mp4', 'persian/vid_85.mp4', 'persian/vid_25.mp4', 'persian/vid_75.mp4', 'persian/vid_66.mp4', 'persian/vid_50.mp4', 'persian/vid_81.mp4', 'persian/vid_60.mp4', 'persian/vid_87.mp4', 'persian/vid_90.mp4', 'persian/vid_35.mp4', 'persian/vid_37.mp4', 'persian/vid_42.mp4', 'persian/vid_69.mp4', 'persian/vid_70.mp4', 'persian/vid_52.mp4', 'persian/vid_53.mp4', 'persian/vid_82.mp4']\n",
    "test_videos = pd.Series(videos).sample(frac=0.25)\n",
    "# print(test_videos.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            filename  culture  frame  face_id  timestamp  confidence  success  \\\n0  persian/vid_1.mp4  persian      1        0      0.000        0.98        1   \n1  persian/vid_1.mp4  persian      2        0      0.033        0.98        1   \n2  persian/vid_1.mp4  persian      3        0      0.067        0.98        1   \n3  persian/vid_1.mp4  persian      4        0      0.100        0.98        1   \n4  persian/vid_1.mp4  persian      5        0      0.133        0.98        1   \n\n   AU01_r  AU02_r  AU04_r  ...  pose_Ry  pose_Rz  gaze_angle_x  gaze_angle_y  \\\n0    0.94    0.24    0.43  ...   -0.451   -0.106         0.408         0.466   \n1    0.17    0.00    0.00  ...   -0.479   -0.113         0.478         0.490   \n2    0.10    0.00    0.00  ...   -0.511   -0.112         0.494         0.471   \n3    0.00    0.00    0.00  ...   -0.537   -0.112         0.540         0.466   \n4    0.00    0.00    0.00  ...   -0.562   -0.115         0.581         0.467   \n\n   none  furious  anger  annoyed  contempt  hatred  \n0   0.0      0.0    0.0      1.0       0.0     0.0  \n1   0.0      0.0    0.0      1.0       0.0     0.0  \n2   0.0      0.0    0.0      1.0       0.0     0.0  \n3   0.0      0.0    0.0      1.0       0.0     0.0  \n4   0.0      0.0    0.0      1.0       0.0     0.0  \n\n[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "metadata_cols = ['frame', 'face_id', 'culture', 'filename', 'timestamp']\n",
    "label_cols = ['none', 'furious', 'anger', 'annoyed', 'contempt', 'hatred']\n",
    "\n",
    "print(X_df.head())\n",
    "\n",
    "train_videos = np.array(list(set(videos) - set(test_videos)))\n",
    "test_df = X_df[X_df['filename'].isin(test_videos)]\n",
    "metadata_test = test_df[metadata_cols]\n",
    "metadata_test.reset_index(inplace=True)\n",
    "y_test = test_df[label_cols].values\n",
    "X_test = test_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success'] + label_cols).values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[800:805,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_test.iloc[800:805]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Training with Cross-validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Classifier Chain\n",
    "Choose one of the classifiers for CC: base_knn, base_xgb"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1-th split: train: 54, test: 14\n",
      "['persian/vid_78.mp4' 'persian/vid_15.mp4' 'persian/vid_64.mp4'\n",
      " 'persian/vid_51.mp4' 'persian/vid_74.mp4' 'persian/vid_86.mp4'\n",
      " 'persian/vid_29.mp4' 'persian/vid_2.mp4' 'persian/vid_96.mp4'\n",
      " 'persian/vid_35.mp4' 'persian/vid_59.mp4' 'persian/vid_8.mp4'\n",
      " 'persian/vid_89.mp4' 'persian/vid_37.mp4' 'persian/vid_52.mp4'\n",
      " 'persian/vid_43.mp4' 'persian/vid_22.mp4' 'persian/vid_45.mp4'\n",
      " 'persian/vid_6.mp4' 'persian/vid_79.mp4' 'persian/vid_82.mp4'\n",
      " 'persian/vid_10.mp4' 'persian/vid_60.mp4' 'persian/vid_25.mp4'\n",
      " 'persian/vid_16.mp4' 'persian/vid_50.mp4' 'persian/vid_13.mp4'\n",
      " 'persian/vid_41.mp4' 'persian/vid_19.mp4' 'persian/vid_27.mp4'\n",
      " 'persian/vid_85.mp4' 'persian/vid_23.mp4' 'persian/vid_56.mp4'\n",
      " 'persian/vid_76.mp4' 'persian/vid_4.mp4' 'persian/vid_12.mp4'\n",
      " 'persian/vid_88.mp4' 'persian/vid_94.mp4' 'persian/vid_70.mp4'\n",
      " 'persian/vid_68.mp4' 'persian/vid_92.mp4' 'persian/vid_67.mp4'\n",
      " 'persian/vid_66.mp4' 'persian/vid_91.mp4' 'persian/vid_48.mp4'\n",
      " 'persian/vid_90.mp4' 'persian/vid_83.mp4' 'persian/vid_62.mp4'\n",
      " 'persian/vid_69.mp4' 'persian/vid_1.mp4' 'persian/vid_5.mp4'\n",
      " 'persian/vid_33.mp4' 'persian/vid_80.mp4' 'persian/vid_87.mp4']\n",
      "Training+validation data size:  4718\n",
      "Training data size:  4718\n",
      "Validation data size:  1253\n",
      "CC Validation Jaccard Score:\n",
      "  0.2273210960361798\n",
      "2-th split: train: 54, test: 14\n",
      "['persian/vid_78.mp4' 'persian/vid_15.mp4' 'persian/vid_58.mp4'\n",
      " 'persian/vid_51.mp4' 'persian/vid_74.mp4' 'persian/vid_86.mp4'\n",
      " 'persian/vid_29.mp4' 'persian/vid_2.mp4' 'persian/vid_96.mp4'\n",
      " 'persian/vid_59.mp4' 'persian/vid_8.mp4' 'persian/vid_89.mp4'\n",
      " 'persian/vid_37.mp4' 'persian/vid_52.mp4' 'persian/vid_43.mp4'\n",
      " 'persian/vid_22.mp4' 'persian/vid_45.mp4' 'persian/vid_79.mp4'\n",
      " 'persian/vid_10.mp4' 'persian/vid_60.mp4' 'persian/vid_25.mp4'\n",
      " 'persian/vid_16.mp4' 'persian/vid_97.mp4' 'persian/vid_3.mp4'\n",
      " 'persian/vid_50.mp4' 'persian/vid_13.mp4' 'persian/vid_41.mp4'\n",
      " 'persian/vid_27.mp4' 'persian/vid_21.mp4' 'persian/vid_44.mp4'\n",
      " 'persian/vid_77.mp4' 'persian/vid_23.mp4' 'persian/vid_56.mp4'\n",
      " 'persian/vid_34.mp4' 'persian/vid_4.mp4' 'persian/vid_12.mp4'\n",
      " 'persian/vid_88.mp4' 'persian/vid_70.mp4' 'persian/vid_92.mp4'\n",
      " 'persian/vid_72.mp4' 'persian/vid_66.mp4' 'persian/vid_46.mp4'\n",
      " 'persian/vid_48.mp4' 'persian/vid_38.mp4' 'persian/vid_75.mp4'\n",
      " 'persian/vid_95.mp4' 'persian/vid_83.mp4' 'persian/vid_69.mp4'\n",
      " 'persian/vid_14.mp4' 'persian/vid_1.mp4' 'persian/vid_57.mp4'\n",
      " 'persian/vid_33.mp4' 'persian/vid_80.mp4' 'persian/vid_87.mp4']\n",
      "Training+validation data size:  5082\n",
      "Training data size:  5082\n",
      "Validation data size:  889\n",
      "CC Validation Jaccard Score:\n",
      "  0.20978627671541059\n",
      "3-th split: train: 54, test: 14\n",
      "['persian/vid_78.mp4' 'persian/vid_15.mp4' 'persian/vid_58.mp4'\n",
      " 'persian/vid_64.mp4' 'persian/vid_51.mp4' 'persian/vid_74.mp4'\n",
      " 'persian/vid_86.mp4' 'persian/vid_29.mp4' 'persian/vid_96.mp4'\n",
      " 'persian/vid_35.mp4' 'persian/vid_59.mp4' 'persian/vid_8.mp4'\n",
      " 'persian/vid_37.mp4' 'persian/vid_52.mp4' 'persian/vid_43.mp4'\n",
      " 'persian/vid_45.mp4' 'persian/vid_6.mp4' 'persian/vid_79.mp4'\n",
      " 'persian/vid_82.mp4' 'persian/vid_60.mp4' 'persian/vid_16.mp4'\n",
      " 'persian/vid_97.mp4' 'persian/vid_3.mp4' 'persian/vid_50.mp4'\n",
      " 'persian/vid_13.mp4' 'persian/vid_19.mp4' 'persian/vid_21.mp4'\n",
      " 'persian/vid_44.mp4' 'persian/vid_85.mp4' 'persian/vid_77.mp4'\n",
      " 'persian/vid_23.mp4' 'persian/vid_34.mp4' 'persian/vid_76.mp4'\n",
      " 'persian/vid_12.mp4' 'persian/vid_88.mp4' 'persian/vid_94.mp4'\n",
      " 'persian/vid_70.mp4' 'persian/vid_68.mp4' 'persian/vid_72.mp4'\n",
      " 'persian/vid_67.mp4' 'persian/vid_66.mp4' 'persian/vid_46.mp4'\n",
      " 'persian/vid_91.mp4' 'persian/vid_48.mp4' 'persian/vid_38.mp4'\n",
      " 'persian/vid_75.mp4' 'persian/vid_90.mp4' 'persian/vid_95.mp4'\n",
      " 'persian/vid_62.mp4' 'persian/vid_14.mp4' 'persian/vid_5.mp4'\n",
      " 'persian/vid_57.mp4' 'persian/vid_80.mp4' 'persian/vid_87.mp4']\n",
      "Training+validation data size:  4710\n",
      "Training data size:  4710\n",
      "Validation data size:  1261\n",
      "CC Validation Jaccard Score:\n",
      "  0.232355273592387\n",
      "4-th split: train: 55, test: 13\n",
      "['persian/vid_78.mp4' 'persian/vid_15.mp4' 'persian/vid_58.mp4'\n",
      " 'persian/vid_64.mp4' 'persian/vid_74.mp4' 'persian/vid_86.mp4'\n",
      " 'persian/vid_29.mp4' 'persian/vid_2.mp4' 'persian/vid_96.mp4'\n",
      " 'persian/vid_35.mp4' 'persian/vid_8.mp4' 'persian/vid_89.mp4'\n",
      " 'persian/vid_52.mp4' 'persian/vid_43.mp4' 'persian/vid_22.mp4'\n",
      " 'persian/vid_6.mp4' 'persian/vid_82.mp4' 'persian/vid_10.mp4'\n",
      " 'persian/vid_25.mp4' 'persian/vid_16.mp4' 'persian/vid_97.mp4'\n",
      " 'persian/vid_3.mp4' 'persian/vid_41.mp4' 'persian/vid_19.mp4'\n",
      " 'persian/vid_27.mp4' 'persian/vid_21.mp4' 'persian/vid_44.mp4'\n",
      " 'persian/vid_85.mp4' 'persian/vid_77.mp4' 'persian/vid_23.mp4'\n",
      " 'persian/vid_56.mp4' 'persian/vid_34.mp4' 'persian/vid_76.mp4'\n",
      " 'persian/vid_4.mp4' 'persian/vid_94.mp4' 'persian/vid_70.mp4'\n",
      " 'persian/vid_68.mp4' 'persian/vid_92.mp4' 'persian/vid_72.mp4'\n",
      " 'persian/vid_67.mp4' 'persian/vid_46.mp4' 'persian/vid_91.mp4'\n",
      " 'persian/vid_38.mp4' 'persian/vid_75.mp4' 'persian/vid_90.mp4'\n",
      " 'persian/vid_95.mp4' 'persian/vid_83.mp4' 'persian/vid_62.mp4'\n",
      " 'persian/vid_69.mp4' 'persian/vid_14.mp4' 'persian/vid_1.mp4'\n",
      " 'persian/vid_5.mp4' 'persian/vid_57.mp4' 'persian/vid_33.mp4'\n",
      " 'persian/vid_80.mp4']\n",
      "Training+validation data size:  4788\n",
      "Training data size:  4788\n",
      "Validation data size:  1183\n",
      "CC Validation Jaccard Score:\n",
      "  0.21062271062271062\n",
      "5-th split: train: 55, test: 13\n",
      "['persian/vid_58.mp4' 'persian/vid_64.mp4' 'persian/vid_51.mp4'\n",
      " 'persian/vid_2.mp4' 'persian/vid_35.mp4' 'persian/vid_59.mp4'\n",
      " 'persian/vid_89.mp4' 'persian/vid_37.mp4' 'persian/vid_22.mp4'\n",
      " 'persian/vid_45.mp4' 'persian/vid_6.mp4' 'persian/vid_79.mp4'\n",
      " 'persian/vid_82.mp4' 'persian/vid_10.mp4' 'persian/vid_60.mp4'\n",
      " 'persian/vid_25.mp4' 'persian/vid_97.mp4' 'persian/vid_3.mp4'\n",
      " 'persian/vid_50.mp4' 'persian/vid_13.mp4' 'persian/vid_41.mp4'\n",
      " 'persian/vid_19.mp4' 'persian/vid_27.mp4' 'persian/vid_21.mp4'\n",
      " 'persian/vid_44.mp4' 'persian/vid_85.mp4' 'persian/vid_77.mp4'\n",
      " 'persian/vid_56.mp4' 'persian/vid_34.mp4' 'persian/vid_76.mp4'\n",
      " 'persian/vid_4.mp4' 'persian/vid_12.mp4' 'persian/vid_88.mp4'\n",
      " 'persian/vid_94.mp4' 'persian/vid_68.mp4' 'persian/vid_92.mp4'\n",
      " 'persian/vid_72.mp4' 'persian/vid_67.mp4' 'persian/vid_66.mp4'\n",
      " 'persian/vid_46.mp4' 'persian/vid_91.mp4' 'persian/vid_48.mp4'\n",
      " 'persian/vid_38.mp4' 'persian/vid_75.mp4' 'persian/vid_90.mp4'\n",
      " 'persian/vid_95.mp4' 'persian/vid_83.mp4' 'persian/vid_62.mp4'\n",
      " 'persian/vid_69.mp4' 'persian/vid_14.mp4' 'persian/vid_1.mp4'\n",
      " 'persian/vid_5.mp4' 'persian/vid_57.mp4' 'persian/vid_33.mp4'\n",
      " 'persian/vid_87.mp4']\n",
      "Training+validation data size:  4586\n",
      "Training data size:  4586\n",
      "Validation data size:  1385\n",
      "CC Validation Jaccard Score:\n",
      "  0.21010830324909746\n",
      "CC Test Jaccard Score: \n",
      "  0.2504278990158323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "kfold = KFold(5, True, 1)\n",
    "frames_mean_hm_test = []\n",
    "frames_mean_jac_test = []\n",
    "videos_mean_jac_test = []\n",
    "videos_mean_hm_test = []\n",
    "# metadata_test.reset_index(inplace=True)\n",
    "\n",
    "col_indices = {i:label for (i,label) in enumerate(label_cols)}\n",
    "best_val = 0\n",
    "best_model = None\n",
    "splits = kfold.split(train_videos)\n",
    "for (i, (train, test)) in enumerate(splits):\n",
    "    # print(videos[train])\n",
    "    # print(videos[test])\n",
    "    print('%d-th split: train: %d, test: %d' % (i+1, len(train_videos[train]), len(train_videos[test])))\n",
    "    train_df = X_df[X_df['filename'].isin(train_videos[train])]\n",
    "    print(train_videos[train])\n",
    "    train_metadata = train_df[metadata_cols]\n",
    "    print('Training+validation data size: ', train_df.shape[0])\n",
    "    y_train = train_df[label_cols].values\n",
    "    X_train = train_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success'] + label_cols).values\n",
    "    valid_df = X_df[X_df['filename'].isin(train_videos[test])]\n",
    "    y_valid = valid_df[label_cols].values\n",
    "    X_valid = valid_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success'] + label_cols).values\n",
    "    # X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "    print('Training data size: ', X_train.shape[0])\n",
    "    print('Validation data size: ', X_valid.shape[0])\n",
    "    base_knn =  KNeighborsClassifier(n_neighbors=5,)\n",
    "    base_xgb = XGBClassifier(objective=\"binary:logistic\", learning_rate=0.2, eval_metric='logloss')\n",
    "    base_rf = RandomForestClassifier()\n",
    "\n",
    "    # ovr = MultiOutputClassifier(base_xgb)\n",
    "    # ovr.fit(X_train, y_train)\n",
    "    # valid_pred_ovr = ovr.predict(X_valid)\n",
    "    # ovr_jaccard_score = jaccard_score(y_valid, valid_pred_ovr, average='samples')\n",
    "    # ovr_ham_loss = metrics.hamming_loss(y_valid, valid_pred_ovr)\n",
    "    # print(\"One-vs-Rest validation Jaccard score:\" , ovr_jaccard_score)\n",
    "    # print(\"One-vs-Rest validation Hamming loss: \" , ovr_ham_loss)\n",
    "\n",
    "   \n",
    "    # Y_pred_ovr = ovr.predict(X_test)\n",
    "    # a = jaccard_score(y_test, Y_pred_ovr, average='samples')\n",
    "    # b = metrics.hamming_loss(y_test, Y_pred_ovr)\n",
    "    # # print(Y_pred_ovr[800:805,:])\n",
    "    # # print(y_test[800:805,:])\n",
    "\n",
    "    # print(\"One-vs-Rest test Jaccard score: \", a)\n",
    "    # print(\"One-vs-Rest test Hamming loss: \" , b)\n",
    "    \n",
    "    \n",
    "    chains = [ClassifierChain(base_knn, order='random', random_state=0) for i in range(7)]\n",
    "    best_model_index = 0\n",
    "    best_jac = 0            \n",
    "    for j, model in enumerate(chains):\n",
    "        model.fit(X_train, y_train)\n",
    "        valid_pred = model.predict(X_valid)\n",
    "        val_score =jaccard_score(y_valid, valid_pred, average='samples')\n",
    "        if val_score > best_jac:\n",
    "            best_model_index = j\n",
    "            best_jac = val_score\n",
    "            \n",
    "        \n",
    "    # predict on validation data\n",
    "    valid_pred_chains = chains[best_model_index].predict(X_valid)\n",
    "    chain_jaccard_scores = jaccard_score(y_valid, valid_pred_chains >= .5,\n",
    "                                    average='samples')\n",
    "\n",
    "    \n",
    "    print(\"CC Validation Jaccard Score:\\n \", chain_jaccard_scores)\n",
    "    if (chain_jaccard_scores > best_val):\n",
    "        best_val = chain_jaccard_scores\n",
    "        best_model = chains[best_model_index]\n",
    "    \n",
    "\n",
    "# test on test data\n",
    "Y_pred_chains = best_model.predict(X_test)\n",
    "chain_jaccard_scores = jaccard_score(y_test, Y_pred_chains >= .5,\n",
    "                                average='samples')\n",
    "                \n",
    "frames_mean_jac_test.append(np.mean(chain_jaccard_scores))\n",
    "print(\"CC Test Jaccard Score: \\n \", chain_jaccard_scores)\n",
    "\n",
    "## voting predicted labels\n",
    "# test_result_df = pd.DataFrame(columns=metadata_cols, data=metadata_test.values)\n",
    "# test_result_df.update(metadata_test)\n",
    "temp_df = pd.DataFrame(data=Y_pred_chains, columns=label_cols)\n",
    "test_result_df = pd.concat([metadata_test, temp_df], axis=1)\n",
    "video_groups = test_result_df.groupby('filename')[label_cols].sum()\n",
    "ground_truth_video_labels = []\n",
    "for v, row in video_groups.iterrows():\n",
    "    # number of 1s in ground truth labels\n",
    "    ground_truth_video_labels.append(test_df[test_df['filename'] == v].iloc[0][label_cols])\n",
    "    \n",
    "    # num_1s = test_df[test_df['filename'] == v].iloc[0][label_cols].sum()\n",
    "    # num_1s = int(num_1s)\n",
    "    # # ##### TODO: Bug is somewhere here:\n",
    "    # a = np.argsort(video_groups.loc[v].values)\n",
    "    # for i in range(len(a) - 1, len(a) - num_1s - 1, -1):\n",
    "    #     video_groups.loc[v][a[i]] = 1\n",
    "    # for i in range(0, len(a) - num_1s):\n",
    "    #     video_groups.loc[v][a[i]] = 0\n",
    "\n",
    "    # num_1s = test_df[test_df['filename'] == v].iloc[0][label_cols].sum()\n",
    "    frames = test_df[test_df['filename'] == v].shape[0]\n",
    "    # print(num_1s)\n",
    "    for i in label_ratio.keys():\n",
    "        prediction_ratio = row[i]/frames\n",
    "        row[i] = 1 if prediction_ratio >= label_ratio[i] else 0\n",
    "        # row[i] = prediction_ratio\n",
    "\n",
    "    \n",
    "# print(np.array(ground_truth_video_labels,  dtype=int).shape)\n",
    "# print(video_groups.values.shape)\n",
    "\n",
    "# j = metrics.jaccard_score(np.array(ground_truth_video_labels,  dtype=int), video_groups.values, average='samples')\n",
    "# h = metrics.hamming_loss(np.array(ground_truth_video_labels,  dtype=int), video_groups.values)\n",
    "# videos_mean_jac_test.append(j)\n",
    "# videos_mean_hm_test.append(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "np.array(ground_truth_video_labels,  dtype=int)"
   ]
  },
  {
   "source": [
    "## Classification Report"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------- Frame-level F1 -----------------\n              precision    recall  f1-score   support\n\n        none       0.37      0.13      0.19       721\n     furious       0.60      0.37      0.46       825\n       anger       0.47      0.46      0.46      1355\n     annoyed       0.12      0.18      0.14       422\n    contempt       0.33      0.28      0.30       630\n      hatred       0.47      0.11      0.18      1005\n\n   micro avg       0.40      0.28      0.33      4958\n   macro avg       0.39      0.25      0.29      4958\nweighted avg       0.43      0.28      0.32      4958\n samples avg       0.41      0.27      0.30      4958\n\n------------------- Video-level F1 -----------------\n              precision    recall  f1-score   support\n\n        none       0.50      0.33      0.40         3\n     furious       0.67      0.40      0.50         5\n       anger       0.75      0.60      0.67        10\n     annoyed       0.12      0.20      0.15         5\n    contempt       0.29      0.33      0.31         6\n      hatred       0.50      0.20      0.29         5\n\n   micro avg       0.43      0.38      0.41        34\n   macro avg       0.47      0.34      0.39        34\nweighted avg       0.51      0.38      0.42        34\n samples avg       0.41      0.37      0.37        34\n\n"
     ]
    }
   ],
   "source": [
    "print('------------------- Frame-level F1 -----------------')\n",
    "print(metrics.classification_report(y_test, Y_pred_chains, target_names=label_cols))\n",
    "print('------------------- Video-level F1 -----------------')\n",
    "print(metrics.classification_report(np.array(ground_truth_video_labels,  dtype=int),  video_groups.values, target_names=label_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------- Frame-level Jaccard -----------------')\n",
    "print(metrics.jaccard_score(y_test, Y_pred_chains, average='samples'))\n",
    "print('------------------- Video-level Jaccard -----------------')\n",
    "print(metrics.jaccard_score(np.array(ground_truth_video_labels,  dtype=int),  video_groups.values, average='samples'))"
   ]
  },
  {
   "source": [
    "Print average of metrics\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F-jac: \", np.mean(frames_mean_jac_test))\n",
    "print(\"V-jac: \", np.mean(videos_mean_jac_test))\n",
    "print(\"F-ham: \", np.mean(frames_mean_hm_test))\n",
    "print(\"V-ham: \", np.mean(videos_mean_hm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_mean_jac_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_videos.to_list())"
   ]
  },
  {
   "source": [
    "## Confused frames\n",
    "The cell below finds frames that are misclassified"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Confusions\n",
    "confused = 0\n",
    "# for i,_ in enumerate(y_test):\n",
    "for i in range(450, 550):\n",
    "    if np.subtract(y_test[i], test_result_df.iloc[i][label_cols].to_numpy(dtype=int)).sum() != 0.0:\n",
    "        confused += 1\n",
    "        print(metadata_test.iloc[i], \"------- Actual: \", y_test[i], \" ----- pred: \", Y_pred_chains[i])\n",
    "print(\"confused: \", confused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F-jac: \", np.mean(frames_mean_jac_test))\n",
    "print(\"V-jac: \", np.mean(videos_mean_jac_test))\n",
    "print(\"F-ham: \", np.mean(frames_mean_hm_test))\n",
    "print(\"V-ham: \", np.mean(videos_mean_hm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.grid(True)\n",
    "ax.set_title('CC Jaccard Score')\n",
    "ax.set_xticks(range(0,7))\n",
    "ax.set_xticklabels(range(0,7))\n",
    "ax.set_ylabel('Jaccard Similarity Score')\n",
    "ax.set_ylim([0.0, 1.1])\n",
    "\n",
    "plt.plot(frames_mean_jac_test, label='Frames Jaccard Score', color='blue')\n",
    "plt.plot(videos_mean_jac_test, label='Video Jaccard Score', color='green')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.grid(True)\n",
    "ax.set_title('CC Hamming Loss')\n",
    "ax.set_xticks(range(0,7))\n",
    "ax.set_xticklabels(range(0,7))\n",
    "ax.set_ylabel('Hamming Distance Loss')\n",
    "ax.set_ylim([0.00, 1.0])\n",
    "# ax.legend(('Frames Hamming Loss','Video Hamming Loss' ))\n",
    "plt.plot(frames_mean_hm_test, label='Frames Hamming Loss', color='red')\n",
    "plt.plot(videos_mean_hm_test, label='Video Hamming Loss', color='green')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### ML KNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training+validation data size:  4718\n",
      "Training data size:  4718\n",
      "Validation data size:  1253\n",
      "Validation Jaccard Score:\n",
      " \n",
      "Training+validation data size:  5082\n",
      "Training data size:  5082\n",
      "Validation data size:  889\n",
      "Validation Jaccard Score:\n",
      " \n",
      "Training+validation data size:  4710\n",
      "Training data size:  4710\n",
      "Validation data size:  1261\n",
      "Validation Jaccard Score:\n",
      " \n",
      "Training+validation data size:  4788\n",
      "Training data size:  4788\n",
      "Validation data size:  1183\n",
      "Validation Jaccard Score:\n",
      " \n",
      "Training+validation data size:  4586\n",
      "Training data size:  4586\n",
      "Validation data size:  1385\n",
      "Validation Jaccard Score:\n",
      " \n",
      "Test Jaccard Score:\n",
      "  0.23521074026529737\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN, MLTSVM\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "## MLTSVM is not compatible with later versions of numpy\n",
    "\n",
    "kfold = KFold(5, True, 1)\n",
    "frames_mean_hm_test = []\n",
    "frames_mean_jac_test = []\n",
    "videos_mean_jac_test = []\n",
    "videos_mean_hm_test = []\n",
    "col_indices = {i:label for (i,label) in enumerate(label_cols)}\n",
    "best_val = 0\n",
    "best_model = None\n",
    "splits = kfold.split(train_videos)\n",
    "for (i, (train, test)) in enumerate(splits):\n",
    "    # print('%d-th split: train: %d, validation: %d' % (i+1, len(videos[train]), len(videos[test])))\n",
    "    train_df = X_df[X_df['filename'].isin(train_videos[train])]\n",
    "    train_metadata = train_df[metadata_cols]\n",
    "    print('Training+validation data size: ', train_df.shape[0])\n",
    "    y_train = train_df[label_cols].values\n",
    "    X_train = train_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success'] + label_cols).values\n",
    "    valid_df = X_df[X_df['filename'].isin(train_videos[test])]\n",
    "    y_valid = valid_df[label_cols].values\n",
    "    X_valid = valid_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success']+ label_cols).values\n",
    "    \n",
    "    print('Training data size: ', X_train.shape[0])\n",
    "    print('Validation data size: ', X_valid.shape[0])\n",
    "    classifier = MLkNN(k=5)\n",
    "    # classifier = MLTSVM(c_k = 2**-1)\n",
    "    prediction = classifier.fit(X_train, y_train).predict(X_valid)\n",
    "\n",
    "    # Predicting on validation set\n",
    "    val_score = metrics.jaccard_score(y_valid, prediction, average='samples')\n",
    "    print(\"Validation Jaccard Score:\\n \", val_score)\n",
    "    if val_score > best_jac:\n",
    "        best_model = classifier\n",
    "        best_jac = val_score\n",
    "\n",
    "# Predicting on test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "jac_score = jaccard_score(y_test, y_test_pred,  average='samples')\n",
    "frames_mean_jac_test.append(jac_score)\n",
    "print(\"Test Jaccard Score:\\n \", jac_score)\n",
    "\n",
    "\n",
    "# building test dataframe to vote labels\n",
    "# test_result_df = pd.DataFrame(columns=metadata_cols, data=metadata_test.values)\n",
    "# test_result_df.update(metadata_test)\n",
    "# print(\"^^^^^^^^\", y_test_pred.toarray().shape)\n",
    "temp_df = pd.DataFrame(data=y_test_pred.toarray(), columns=label_cols)\n",
    "test_result_df = pd.concat([metadata_test, temp_df], axis=1)\n",
    "\n",
    "# print(test_result_df.head())\n",
    "video_groups = test_result_df.groupby('filename')[label_cols].apply(lambda x : x.astype(int).sum())\n",
    "# for name, group in video_groups:\n",
    "#     print(name)\n",
    "#     print(group)\n",
    "#     print(\"\\n\") \n",
    "ground_truth_video_labels = []\n",
    "for v, row in video_groups.iterrows():\n",
    "    # number of 1s in ground truth labels\n",
    "    ground_truth_video_labels.append(test_df[test_df['filename'] == v].iloc[0][label_cols])\n",
    "    \n",
    "    # num_1s = test_df[test_df['filename'] == v].iloc[0][label_cols].sum()\n",
    "    # num_1s = int(num_1s)\n",
    "    # # ##### TODO: Bug is somewhere here:\n",
    "    # a = np.argsort(video_groups.loc[v].values)\n",
    "    # for i in range(len(a) - 1, len(a) - num_1s - 1, -1):\n",
    "    #     video_groups.loc[v][a[i]] = 1\n",
    "    # for i in range(0, len(a) - num_1s):\n",
    "    #     video_groups.loc[v][a[i]] = 0\n",
    "\n",
    "    # num_1s = test_df[test_df['filename'] == v].iloc[0][label_cols].sum()\n",
    "    frames = test_df[test_df['filename'] == v].shape[0]\n",
    "    # print(num_1s)\n",
    "    for i in label_ratio.keys():\n",
    "        # print(type(frames))\n",
    "        prediction_ratio = row[i]/frames\n",
    "        # print(prediction_ratio)\n",
    "        row[i] = 1 if prediction_ratio >= label_ratio[i] else 0\n",
    "\n",
    "\n",
    "# j = metrics.jaccard_score(np.array(ground_truth_video_labels,  dtype=int), video_groups.values, average='samples')\n",
    "# h = metrics.hamming_loss(np.array(ground_truth_video_labels,  dtype=int), video_groups.values)\n",
    "# videos_mean_jac_test.append(j)\n",
    "# videos_mean_hm_test.append(h)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.grid(True)\n",
    "ax.set_title('MLKNN Jaccard Score')\n",
    "ax.set_xticks(range(0,7))\n",
    "ax.set_xticklabels(range(0,7))\n",
    "ax.set_ylabel('Jaccard Similarity Score')\n",
    "ax.set_ylim([0.00, 1.0])\n",
    "\n",
    "plt.plot(frames_mean_jac_test, label='Frames Jaccard Score', color='blue')\n",
    "plt.plot(videos_mean_jac_test, label='Video Jaccard Score', color='green')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F-jac: \", np.mean(frames_mean_jac_test))\n",
    "print(\"V-jac: \", np.mean(videos_mean_jac_test))\n",
    "print(\"F-ham: \", np.mean(frames_mean_hm_test))\n",
    "print(\"V-ham: \", np.mean(videos_mean_hm_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_mean_jac_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.grid(True)\n",
    "ax.set_title('MLKNN Hamming Loss')\n",
    "ax.set_xticks(range(0,7))\n",
    "ax.set_xticklabels(range(0,7))\n",
    "ax.set_ylabel('Hamming Distance Loss')\n",
    "ax.set_ylim([0.00, 1.0])\n",
    "# ax.legend(('Frames Hamming Loss','Video Hamming Loss' ))\n",
    "plt.plot(frames_mean_hm_test, label='Frames Hamming Loss', color='red')\n",
    "plt.plot(videos_mean_hm_test, label='Video Hamming Loss', color='green')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(frames_mean_hm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "source": [
    "Multilabel confusion matrix puts TN at (0,0) and TP at (1,1) position thanks @Kenneth Witham for pointing out.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "`support`: The number of occurrences of each label in y_true."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------- Frame-level F1 -----------------\n              precision    recall  f1-score   support\n\n        none       0.37      0.07      0.11       721\n     furious       0.62      0.36      0.46       825\n       anger       0.46      0.53      0.49      1355\n     annoyed       0.13      0.28      0.18       422\n    contempt       0.39      0.18      0.24       630\n      hatred       0.47      0.11      0.18      1005\n\n   micro avg       0.39      0.29      0.33      4958\n   macro avg       0.41      0.26      0.28      4958\nweighted avg       0.44      0.29      0.31      4958\n samples avg       0.38      0.27      0.29      4958\n\n------------------- Video-level F1 -----------------\n              precision    recall  f1-score   support\n\n        none       0.00      0.00      0.00         3\n     furious       0.67      0.40      0.50         5\n       anger       0.55      0.60      0.57        10\n     annoyed       0.14      0.40      0.21         5\n    contempt       0.67      0.33      0.44         6\n      hatred       0.50      0.20      0.29         5\n\n   micro avg       0.39      0.38      0.39        34\n   macro avg       0.42      0.32      0.34        34\nweighted avg       0.47      0.38      0.39        34\n samples avg       0.37      0.37      0.35        34\n\n"
     ]
    }
   ],
   "source": [
    "print('------------------- Frame-level F1 -----------------')\n",
    "print(metrics.classification_report(y_test, y_test_pred, target_names=label_cols))\n",
    "\n",
    "print('------------------- Video-level F1 -----------------')\n",
    "print(metrics.classification_report(np.array(ground_truth_video_labels,  dtype=int),  video_groups.values, target_names=label_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------- Frame-level Jaccard -----------------')\n",
    "print(metrics.jaccard_score(y_test, y_test_pred, average='samples'))\n",
    "\n",
    "print('------------------- Video-level Jaccard -----------------')\n",
    "print(metrics.jaccard_score(np.array(ground_truth_video_labels,  dtype=int),  video_groups.values, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(type(y_test[0]))\n",
    "print(type(y_test_pred[0].toarray()))\n",
    "for i in range(len(y_test)):\n",
    "    if metrics.hamming_loss(y_test[i].flatten(), Y_pred_chains[4][i].flatten()) > 0:\n",
    "        print(\"Ground Truth: \", y_test[i], \", Prediction: \", Y_pred_chains[0][i])\n",
    "        print(\"Video data: \", metadata_test.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[800:805])\n",
    "print(metadata_test[800:805])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_test))\n",
    "print(len(metadata_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(input: str):\n",
    "    input = 'persian/' + input +\".mp4\"\n",
    "    return input\n",
    "X_df = pd.read_csv('../new_data/Persian/persian_dataset.csv', index_col=None)\n",
    "X_df['filename'] = X_df['filename'].apply(clean)\n",
    "X_df.to_csv('../new_data/Persian/persian_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}