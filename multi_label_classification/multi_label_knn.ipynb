{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tslearn.metrics import dtw, soft_dtw\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from sklearn.utils.validation import _check_large_sparse\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, jaccard_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_df(item_lists, unique_items):\n",
    "# Create empty dict\n",
    "    bool_dict = {}\n",
    "    \n",
    "    # Loop through all the tags\n",
    "    for i, item in enumerate(unique_items):\n",
    "        \n",
    "        # Apply boolean mask\n",
    "        bool_dict[item] = item_lists.apply(lambda x: 1 if item in x else 0)\n",
    "            \n",
    "    # Return the results as a dataframe\n",
    "    return pd.DataFrame(bool_dict)\n",
    "\n",
    "def to_1D(series):\n",
    "    return pd.Series([x for _list in series for x in _list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                none  furious  anger  annoyed  contempt  disgust  hatred\n",
       "filename                                                                \n",
       "na/vid_1.mp4       1        0      0        0         0        0       0\n",
       "na/vid_100.mp4     0        1      0        0         0        0       0\n",
       "na/vid_101.mp4     0        1      0        0         0        0       0\n",
       "na/vid_102.mp4     0        0      1        0         0        0       0\n",
       "na/vid_104.mp4     0        0      1        0         0        0       0\n",
       "...              ...      ...    ...      ...       ...      ...     ...\n",
       "na/vid_90.mp4      0        0      1        0         0        0       0\n",
       "na/vid_92.mp4      0        0      1        0         0        0       0\n",
       "na/vid_93.mp4      0        0      1        0         0        0       0\n",
       "na/vid_95.mp4      0        0      1        0         0        0       1\n",
       "na/vid_97.mp4      0        1      0        0         0        0       0\n",
       "\n",
       "[96 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>none</th>\n      <th>furious</th>\n      <th>anger</th>\n      <th>annoyed</th>\n      <th>contempt</th>\n      <th>disgust</th>\n      <th>hatred</th>\n    </tr>\n    <tr>\n      <th>filename</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>na/vid_1.mp4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>na/vid_100.mp4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>na/vid_101.mp4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>na/vid_102.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>na/vid_104.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>na/vid_90.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>na/vid_92.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>na/vid_93.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>na/vid_95.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>na/vid_97.mp4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>96 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "X_df = pd.read_csv('../new_data/NA/na_dataset.csv', index_col=None)\n",
    "Y_df = pd.read_csv('../new_data/NA/na_labels.csv', usecols=['filename', 'emotions'], index_col='filename')\n",
    "Y_df[\"emotions\"] = Y_df[\"emotions\"].apply(eval)\n",
    "unique_items = to_1D(Y_df[\"emotions\"]).unique()\n",
    "labels_expanded = boolean_df(Y_df['emotions'], unique_items)\n",
    "labels_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_expanded.loc['na/vid_1.mp4']['none':'hatred'].to_list()\n",
    "\n",
    "for c in labels_expanded.columns: \n",
    "    X_df[c]=np.nan \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       filename         culture  frame  face_id  timestamp  confidence  \\\n",
       "0  na/vid_1.mp4  north american      1        0      0.000        0.98   \n",
       "1  na/vid_1.mp4  north american      2        0      0.017        0.98   \n",
       "2  na/vid_1.mp4  north american      3        0      0.033        0.98   \n",
       "3  na/vid_1.mp4  north american      4        0      0.050        0.98   \n",
       "4  na/vid_1.mp4  north american      5        0      0.067        0.98   \n",
       "\n",
       "   success  AU01_r  AU02_r  AU04_r  ...  pose_Rz  gaze_angle_x  gaze_angle_y  \\\n",
       "0        1    1.45    1.86     0.0  ...   -0.063         0.107         0.353   \n",
       "1        1    1.50    1.98     0.0  ...   -0.064         0.101         0.347   \n",
       "2        1    1.57    1.98     0.0  ...   -0.065         0.100         0.348   \n",
       "3        1    1.56    1.99     0.0  ...   -0.065         0.100         0.348   \n",
       "4        1    1.40    1.94     0.0  ...   -0.075         0.093         0.356   \n",
       "\n",
       "   none  furious  anger  annoyed  contempt  disgust  hatred  \n",
       "0   NaN      NaN    NaN      NaN       NaN      NaN     NaN  \n",
       "1   NaN      NaN    NaN      NaN       NaN      NaN     NaN  \n",
       "2   NaN      NaN    NaN      NaN       NaN      NaN     NaN  \n",
       "3   NaN      NaN    NaN      NaN       NaN      NaN     NaN  \n",
       "4   NaN      NaN    NaN      NaN       NaN      NaN     NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>culture</th>\n      <th>frame</th>\n      <th>face_id</th>\n      <th>timestamp</th>\n      <th>confidence</th>\n      <th>success</th>\n      <th>AU01_r</th>\n      <th>AU02_r</th>\n      <th>AU04_r</th>\n      <th>...</th>\n      <th>pose_Rz</th>\n      <th>gaze_angle_x</th>\n      <th>gaze_angle_y</th>\n      <th>none</th>\n      <th>furious</th>\n      <th>anger</th>\n      <th>annoyed</th>\n      <th>contempt</th>\n      <th>disgust</th>\n      <th>hatred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>na/vid_1.mp4</td>\n      <td>north american</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>1.45</td>\n      <td>1.86</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.063</td>\n      <td>0.107</td>\n      <td>0.353</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>na/vid_1.mp4</td>\n      <td>north american</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.017</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>1.50</td>\n      <td>1.98</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.064</td>\n      <td>0.101</td>\n      <td>0.347</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>na/vid_1.mp4</td>\n      <td>north american</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.033</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>1.57</td>\n      <td>1.98</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.065</td>\n      <td>0.100</td>\n      <td>0.348</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>na/vid_1.mp4</td>\n      <td>north american</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.050</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>1.56</td>\n      <td>1.99</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.065</td>\n      <td>0.100</td>\n      <td>0.348</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>na/vid_1.mp4</td>\n      <td>north american</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0.067</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>1.40</td>\n      <td>1.94</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.075</td>\n      <td>0.093</td>\n      <td>0.356</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 36 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in X_df.iterrows():\n",
    "    # print(index, row)\n",
    "    filename = X_df.iloc[index]['filename']\n",
    "    # print(labels_expanded.loc[filename]['none':'hatred'].to_list())\n",
    "    X_df.at[index,'none'] = labels_expanded.at[filename,'none']\n",
    "    X_df.at[index,'furious'] = labels_expanded.at[filename,'furious']\n",
    "    X_df.at[index,'anger'] = labels_expanded.at[filename,'anger']\n",
    "    X_df.at[index,'annoyed'] = labels_expanded.at[filename,'annoyed']\n",
    "    X_df.at[index,'contempt'] = labels_expanded.at[filename,'contempt']\n",
    "    X_df.at[index,'disgust'] = labels_expanded.at[filename,'disgust']\n",
    "    X_df.at[index,'hatred'] = labels_expanded.at[filename,'hatred']"
   ]
  },
  {
   "source": [
    "### Min-Max Scaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             frame      face_id    timestamp   confidence  success  \\\n",
       "count  6876.000000  6876.000000  6876.000000  6876.000000   6876.0   \n",
       "mean     62.283886     0.172484     2.202004     0.964308      1.0   \n",
       "std      54.266866     0.430042     1.992598     0.033154      0.0   \n",
       "min       1.000000     0.000000     0.000000     0.880000      1.0   \n",
       "25%      24.000000     0.000000     0.767000     0.980000      1.0   \n",
       "50%      48.000000     0.000000     1.635000     0.980000      1.0   \n",
       "75%      84.000000     0.000000     2.970000     0.980000      1.0   \n",
       "max     301.000000     2.000000    10.010000     0.980000      1.0   \n",
       "\n",
       "            AU01_r       AU02_r       AU04_r       AU05_r       AU06_r  ...  \\\n",
       "count  6876.000000  6876.000000  6876.000000  6876.000000  6876.000000  ...   \n",
       "mean      0.689620     0.905599     0.453013     0.536358     0.550711  ...   \n",
       "std       0.743647     1.202467     0.695540     0.800871     0.701084  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.490000     0.180000     0.000000     0.000000     0.255000  ...   \n",
       "75%       1.190000     1.570000     0.810000     0.890000     0.900000  ...   \n",
       "max       3.750000     5.000000     3.470000     4.470000     3.600000  ...   \n",
       "\n",
       "           pose_Rz  gaze_angle_x  gaze_angle_y         none      furious  \\\n",
       "count  6876.000000   6876.000000   6876.000000  6876.000000  6876.000000   \n",
       "mean      0.012550      0.010423      0.318281     0.104421     0.115765   \n",
       "std       0.160888      0.314508      0.164934     0.305828     0.319966   \n",
       "min      -0.564000     -0.864000     -0.544000     0.000000     0.000000   \n",
       "25%      -0.090000     -0.183000      0.193000     0.000000     0.000000   \n",
       "50%       0.017000     -0.015000      0.317500     0.000000     0.000000   \n",
       "75%       0.104000      0.222000      0.440000     0.000000     0.000000   \n",
       "max       1.510000      0.977000      0.825000     1.000000     1.000000   \n",
       "\n",
       "             anger      annoyed     contempt      disgust       hatred  \n",
       "count  6876.000000  6876.000000  6876.000000  6876.000000  6876.000000  \n",
       "mean      0.199389     0.385835     0.173211     0.195172     0.017597  \n",
       "std       0.399570     0.486827     0.378457     0.396362     0.131493  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     1.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 34 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frame</th>\n      <th>face_id</th>\n      <th>timestamp</th>\n      <th>confidence</th>\n      <th>success</th>\n      <th>AU01_r</th>\n      <th>AU02_r</th>\n      <th>AU04_r</th>\n      <th>AU05_r</th>\n      <th>AU06_r</th>\n      <th>...</th>\n      <th>pose_Rz</th>\n      <th>gaze_angle_x</th>\n      <th>gaze_angle_y</th>\n      <th>none</th>\n      <th>furious</th>\n      <th>anger</th>\n      <th>annoyed</th>\n      <th>contempt</th>\n      <th>disgust</th>\n      <th>hatred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>6876.0</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>...</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n      <td>6876.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>62.283886</td>\n      <td>0.172484</td>\n      <td>2.202004</td>\n      <td>0.964308</td>\n      <td>1.0</td>\n      <td>0.689620</td>\n      <td>0.905599</td>\n      <td>0.453013</td>\n      <td>0.536358</td>\n      <td>0.550711</td>\n      <td>...</td>\n      <td>0.012550</td>\n      <td>0.010423</td>\n      <td>0.318281</td>\n      <td>0.104421</td>\n      <td>0.115765</td>\n      <td>0.199389</td>\n      <td>0.385835</td>\n      <td>0.173211</td>\n      <td>0.195172</td>\n      <td>0.017597</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>54.266866</td>\n      <td>0.430042</td>\n      <td>1.992598</td>\n      <td>0.033154</td>\n      <td>0.0</td>\n      <td>0.743647</td>\n      <td>1.202467</td>\n      <td>0.695540</td>\n      <td>0.800871</td>\n      <td>0.701084</td>\n      <td>...</td>\n      <td>0.160888</td>\n      <td>0.314508</td>\n      <td>0.164934</td>\n      <td>0.305828</td>\n      <td>0.319966</td>\n      <td>0.399570</td>\n      <td>0.486827</td>\n      <td>0.378457</td>\n      <td>0.396362</td>\n      <td>0.131493</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.880000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>-0.564000</td>\n      <td>-0.864000</td>\n      <td>-0.544000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>24.000000</td>\n      <td>0.000000</td>\n      <td>0.767000</td>\n      <td>0.980000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>-0.090000</td>\n      <td>-0.183000</td>\n      <td>0.193000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>48.000000</td>\n      <td>0.000000</td>\n      <td>1.635000</td>\n      <td>0.980000</td>\n      <td>1.0</td>\n      <td>0.490000</td>\n      <td>0.180000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.255000</td>\n      <td>...</td>\n      <td>0.017000</td>\n      <td>-0.015000</td>\n      <td>0.317500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>84.000000</td>\n      <td>0.000000</td>\n      <td>2.970000</td>\n      <td>0.980000</td>\n      <td>1.0</td>\n      <td>1.190000</td>\n      <td>1.570000</td>\n      <td>0.810000</td>\n      <td>0.890000</td>\n      <td>0.900000</td>\n      <td>...</td>\n      <td>0.104000</td>\n      <td>0.222000</td>\n      <td>0.440000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>301.000000</td>\n      <td>2.000000</td>\n      <td>10.010000</td>\n      <td>0.980000</td>\n      <td>1.0</td>\n      <td>3.750000</td>\n      <td>5.000000</td>\n      <td>3.470000</td>\n      <td>4.470000</td>\n      <td>3.600000</td>\n      <td>...</td>\n      <td>1.510000</td>\n      <td>0.977000</td>\n      <td>0.825000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 34 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = list (\n",
    "    set(X_df.columns.to_list()) - set(['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success', 'none', 'furious', 'anger', 'annoyed', 'contempt', 'disgust', 'hatred'])\n",
    ")\n",
    "scaler = MinMaxScaler()\n",
    "X_df[cols_to_scale] = scaler.fit_transform(X_df[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           filename         culture  frame  face_id  timestamp  confidence  \\\n",
       "6871  na/vid_97.mp4  north american     92        0      3.792        0.88   \n",
       "6872  na/vid_97.mp4  north american     93        0      3.833        0.88   \n",
       "6873  na/vid_97.mp4  north american     94        0      3.875        0.88   \n",
       "6874  na/vid_97.mp4  north american     95        0      3.917        0.88   \n",
       "6875  na/vid_97.mp4  north american     96        0      3.958        0.88   \n",
       "\n",
       "      success    AU01_r  AU02_r    AU04_r  ...   pose_Rz  gaze_angle_x  \\\n",
       "6871        1  0.176000     0.0  0.778098  ...  0.299421      0.241173   \n",
       "6872        1  0.000000     0.0  0.789625  ...  0.305689      0.247148   \n",
       "6873        1  0.021333     0.0  0.821326  ...  0.308100      0.248778   \n",
       "6874        1  0.000000     0.0  0.853026  ...  0.302797      0.239001   \n",
       "6875        1  0.000000     0.0  0.884726  ...  0.296528      0.240630   \n",
       "\n",
       "      gaze_angle_y  none  furious  anger  annoyed  contempt  disgust  hatred  \n",
       "6871      0.589481   0.0      1.0    0.0      0.0       0.0      0.0     0.0  \n",
       "6872      0.584368   0.0      1.0    0.0      0.0       0.0      0.0     0.0  \n",
       "6873      0.579985   0.0      1.0    0.0      0.0       0.0      0.0     0.0  \n",
       "6874      0.598977   0.0      1.0    0.0      0.0       0.0      0.0     0.0  \n",
       "6875      0.604091   0.0      1.0    0.0      0.0       0.0      0.0     0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>culture</th>\n      <th>frame</th>\n      <th>face_id</th>\n      <th>timestamp</th>\n      <th>confidence</th>\n      <th>success</th>\n      <th>AU01_r</th>\n      <th>AU02_r</th>\n      <th>AU04_r</th>\n      <th>...</th>\n      <th>pose_Rz</th>\n      <th>gaze_angle_x</th>\n      <th>gaze_angle_y</th>\n      <th>none</th>\n      <th>furious</th>\n      <th>anger</th>\n      <th>annoyed</th>\n      <th>contempt</th>\n      <th>disgust</th>\n      <th>hatred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6871</th>\n      <td>na/vid_97.mp4</td>\n      <td>north american</td>\n      <td>92</td>\n      <td>0</td>\n      <td>3.792</td>\n      <td>0.88</td>\n      <td>1</td>\n      <td>0.176000</td>\n      <td>0.0</td>\n      <td>0.778098</td>\n      <td>...</td>\n      <td>0.299421</td>\n      <td>0.241173</td>\n      <td>0.589481</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6872</th>\n      <td>na/vid_97.mp4</td>\n      <td>north american</td>\n      <td>93</td>\n      <td>0</td>\n      <td>3.833</td>\n      <td>0.88</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.789625</td>\n      <td>...</td>\n      <td>0.305689</td>\n      <td>0.247148</td>\n      <td>0.584368</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6873</th>\n      <td>na/vid_97.mp4</td>\n      <td>north american</td>\n      <td>94</td>\n      <td>0</td>\n      <td>3.875</td>\n      <td>0.88</td>\n      <td>1</td>\n      <td>0.021333</td>\n      <td>0.0</td>\n      <td>0.821326</td>\n      <td>...</td>\n      <td>0.308100</td>\n      <td>0.248778</td>\n      <td>0.579985</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6874</th>\n      <td>na/vid_97.mp4</td>\n      <td>north american</td>\n      <td>95</td>\n      <td>0</td>\n      <td>3.917</td>\n      <td>0.88</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.853026</td>\n      <td>...</td>\n      <td>0.302797</td>\n      <td>0.239001</td>\n      <td>0.598977</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6875</th>\n      <td>na/vid_97.mp4</td>\n      <td>north american</td>\n      <td>96</td>\n      <td>0</td>\n      <td>3.958</td>\n      <td>0.88</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.884726</td>\n      <td>...</td>\n      <td>0.296528</td>\n      <td>0.240630</td>\n      <td>0.604091</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 36 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "X_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting into train and test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       filename         culture  frame  face_id  timestamp  confidence  \\\n0  na/vid_1.mp4  north american      1        0      0.000        0.98   \n1  na/vid_1.mp4  north american      2        0      0.017        0.98   \n2  na/vid_1.mp4  north american      3        0      0.033        0.98   \n3  na/vid_1.mp4  north american      4        0      0.050        0.98   \n4  na/vid_1.mp4  north american      5        0      0.067        0.98   \n\n   success    AU01_r  AU02_r  AU04_r  ...   pose_Rz  gaze_angle_x  \\\n0        1  0.386667   0.372     0.0  ...  0.241562      0.527431   \n1        1  0.400000   0.396     0.0  ...  0.241080      0.524172   \n2        1  0.418667   0.396     0.0  ...  0.240598      0.523628   \n3        1  0.416000   0.398     0.0  ...  0.240598      0.523628   \n4        1  0.373333   0.388     0.0  ...  0.235776      0.519826   \n\n   gaze_angle_y  none  furious  anger  annoyed  contempt  disgust  hatred  \n0      0.655223   1.0      0.0    0.0      0.0       0.0      0.0     0.0  \n1      0.650840   1.0      0.0    0.0      0.0       0.0      0.0     0.0  \n2      0.651570   1.0      0.0    0.0      0.0       0.0      0.0     0.0  \n3      0.651570   1.0      0.0    0.0      0.0       0.0      0.0     0.0  \n4      0.657414   1.0      0.0    0.0      0.0       0.0      0.0     0.0  \n\n[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "metadata_cols = ['frame', 'face_id', 'culture', 'filename', 'timestamp']\n",
    "print(X_df.head())\n",
    "videos = X_df['filename'].unique()\n",
    "test_videos = pd.Series(videos).sample(frac=0.20)\n",
    "train_videos = np.array(list(set(videos) - set(test_videos)))\n",
    "test_df = X_df[X_df['filename'].isin(test_videos)]\n",
    "metadata_test = test_df[metadata_cols]\n",
    "y_test = test_df[['none', 'furious', 'anger', 'annoyed', 'contempt', 'disgust', 'hatred']].values\n",
    "X_test = test_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success']).values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      frame  face_id         culture       filename  timestamp\n",
       "388       1        0  north american  na/vid_11.mp4      0.000\n",
       "389       2        0  north american  na/vid_11.mp4      0.033\n",
       "390       3        0  north american  na/vid_11.mp4      0.067\n",
       "391       4        0  north american  na/vid_11.mp4      0.100\n",
       "392       5        0  north american  na/vid_11.mp4      0.133\n",
       "...     ...      ...             ...            ...        ...\n",
       "6642    116        0  north american  na/vid_92.mp4      4.792\n",
       "6643    117        0  north american  na/vid_92.mp4      4.833\n",
       "6644    118        0  north american  na/vid_92.mp4      4.875\n",
       "6645    119        0  north american  na/vid_92.mp4      4.917\n",
       "6646    120        0  north american  na/vid_92.mp4      4.958\n",
       "\n",
       "[1274 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frame</th>\n      <th>face_id</th>\n      <th>culture</th>\n      <th>filename</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>388</th>\n      <td>1</td>\n      <td>0</td>\n      <td>north american</td>\n      <td>na/vid_11.mp4</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>389</th>\n      <td>2</td>\n      <td>0</td>\n      <td>north american</td>\n      <td>na/vid_11.mp4</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>3</td>\n      <td>0</td>\n      <td>north american</td>\n      <td>na/vid_11.mp4</td>\n      <td>0.067</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>4</td>\n      <td>0</td>\n      <td>north american</td>\n      <td>na/vid_11.mp4</td>\n      <td>0.100</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>5</td>\n      <td>0</td>\n      <td>north american</td>\n      <td>na/vid_11.mp4</td>\n      <td>0.133</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6642</th>\n      <td>116</td>\n      <td>0</td>\n      <td>north american</td>\n      <td>na/vid_92.mp4</td>\n      <td>4.792</td>\n    </tr>\n    <tr>\n      <th>6643</th>\n      <td>117</td>\n      <td>0</td>\n      <td>north american</td>\n      <td>na/vid_92.mp4</td>\n      <td>4.833</td>\n    </tr>\n    <tr>\n      <th>6644</th>\n      <td>118</td>\n      <td>0</td>\n      <td>north american</td>\n      <td>na/vid_92.mp4</td>\n      <td>4.875</td>\n    </tr>\n    <tr>\n      <th>6645</th>\n      <td>119</td>\n      <td>0</td>\n      <td>north american</td>\n      <td>na/vid_92.mp4</td>\n      <td>4.917</td>\n    </tr>\n    <tr>\n      <th>6646</th>\n      <td>120</td>\n      <td>0</td>\n      <td>north american</td>\n      <td>na/vid_92.mp4</td>\n      <td>4.958</td>\n    </tr>\n  </tbody>\n</table>\n<p>1274 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "metadata_test"
   ]
  },
  {
   "source": [
    "## Cross-validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1-th split: train: 60, test: 15\n",
      "Training+validation data size:  4494\n",
      "Training data size:  3370\n",
      "Validation data size:  1124\n",
      "Validation Jaccard Score:  [array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.])]\n",
      "Test Jaccard Score:  [array([1.        , 1.        , 1.        , 1.        , 0.75471698,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.75471698,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.75471698,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.75471698,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.75471698,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.75471698,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.75471698,\n",
      "       1.        , 0.        ])]\n",
      "2-th split: train: 60, test: 15\n",
      "Training+validation data size:  4489\n",
      "Training data size:  3366\n",
      "Validation data size:  1123\n",
      "Validation Jaccard Score:  [array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.])]\n",
      "Test Jaccard Score:  [array([1.        , 1.        , 0.87323944, 0.99341021, 0.94339623,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 0.87323944, 0.99341021, 0.94339623,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 0.86267606, 0.99835255, 0.94339623,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 0.86267606, 0.99835255, 0.94339623,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 0.86267606, 0.99835255, 0.94339623,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 0.87323944, 0.99341021, 0.94339623,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 0.86267606, 0.99835255, 0.94339623,\n",
      "       1.        , 0.        ])]\n",
      "3-th split: train: 60, test: 15\n",
      "Training+validation data size:  3960\n",
      "Training data size:  2970\n",
      "Validation data size:  990\n",
      "Validation Jaccard Score:  [array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.])]\n",
      "Test Jaccard Score:  [array([1.        , 1.        , 1.        , 1.        , 0.98584906,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.98584906,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.98584906,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.98584906,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.98584906,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.98584906,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.98584906,\n",
      "       1.        , 0.        ])]\n",
      "4-th split: train: 60, test: 15\n",
      "Training+validation data size:  4297\n",
      "Training data size:  3222\n",
      "Validation data size:  1075\n",
      "Validation Jaccard Score:  [array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.])]\n",
      "Test Jaccard Score:  [array([1.        , 1.        , 1.        , 1.        , 0.95754717,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.95754717,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.95754717,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.95754717,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.95754717,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.95754717,\n",
      "       1.        , 0.        ]), array([1.        , 1.        , 1.        , 1.        , 0.95754717,\n",
      "       1.        , 0.        ])]\n",
      "5-th split: train: 60, test: 15\n",
      "Training+validation data size:  4164\n",
      "Training data size:  3123\n",
      "Validation data size:  1041\n",
      "Validation Jaccard Score:  [array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.]), array([1., 1., 1., 1., 1., 1., 0.])]\n",
      "Test Jaccard Score:  [array([1.        , 0.98245614, 1.        , 1.        , 0.99528302,\n",
      "       1.        , 0.        ]), array([1.        , 0.98245614, 1.        , 1.        , 0.99528302,\n",
      "       1.        , 0.        ]), array([1.        , 0.98245614, 1.        , 1.        , 0.99528302,\n",
      "       1.        , 0.        ]), array([1.        , 0.98245614, 1.        , 1.        , 0.99528302,\n",
      "       1.        , 0.        ]), array([1.        , 0.98245614, 1.        , 1.        , 0.99528302,\n",
      "       1.        , 0.        ]), array([1.        , 0.98245614, 1.        , 1.        , 0.99528302,\n",
      "       1.        , 0.        ]), array([1.        , 0.98245614, 1.        , 1.        , 0.99528302,\n",
      "       1.        , 0.        ])]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(5, True, 1)\n",
    "\n",
    "\n",
    "splits = kfold.split(train_videos)\n",
    "for (i, (train, test)) in enumerate(splits):\n",
    "    print('%d-th split: train: %d, test: %d' % (i+1, len(videos[train]), len(videos[test])))\n",
    "    train_df = X_df[X_df['filename'].isin(videos[train])]\n",
    "    train_metadata = train_df[metadata_cols]\n",
    "    print('Training+validation data size: ', train_df.shape[0])\n",
    "    y = train_df[['none', 'furious', 'anger', 'annoyed', 'contempt', 'disgust', 'hatred']].values\n",
    "    X = train_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success']).values\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "    print('Training data size: ', X_train.shape[0])\n",
    "    print('Validation data size: ', X_valid.shape[0])\n",
    "    base_knn =  KNeighborsClassifier(n_neighbors=5,)\n",
    "    chains = [ClassifierChain(base_knn, order='random', random_state=i)\n",
    "            for i in range(7)]\n",
    "    for j, model in enumerate(chains):\n",
    "        model.fit(X_train, y_train)\n",
    "        # valid_pred = model.predict(X_valid)\n",
    "        # val_score =jaccard_score(y_valid, valid_pred, average='samples')\n",
    "        # print('Validation score in model %d: %d' % (j, val_score) )\n",
    "        \n",
    "    # predict on validation data\n",
    "    valid_pred_chains = np.array([chain.predict(X_valid) for chain in\n",
    "                            chains])\n",
    "    chain_accuracy_scores = [jaccard_score(y_valid, valid_pred_chain,\n",
    "                                    average='micro')\n",
    "                    for valid_pred_chain in valid_pred_chains]\n",
    "    \n",
    "    print(\"Validation Jaccard Score:\\n \", chain_accuracy_scores)\n",
    "    # test on test data\n",
    "    Y_pred_chains = np.array([chain.predict(X_test) for chain in\n",
    "                            chains])\n",
    "    chain_accuracy_scores = [jaccard_score(y_test, Y_pred_chain,\n",
    "                                    average='micro')\n",
    "                    for Y_pred_chain in Y_pred_chains]\n",
    "\n",
    "    print(\"Test Jaccard Score: \\n \", chain_accuracy_scores)\n",
    "\n",
    "\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred_chains[3][200:205])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[200:205])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Break data into chunks of 50 frames or less"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped = X_df.groupby(by=['filename', 'face_id'])\n",
    "## Separating test data\n",
    "test_ts_list = list()\n",
    "test_metadata = list()\n",
    "# X_list is video/face frames, divided into 50 frames chunks\n",
    "X_list = []\n",
    "Y_list = []\n",
    "metadata = []\n",
    "frame_limit = 50\n",
    "for key in grouped.groups:\n",
    "    X_group = grouped.get_group(key)\n",
    "    # X_group = X_group.drop(['frame', 'face_id', 'culture', 'filename', 'emotion', 'confidence','success'], axis=1)\n",
    "    if len(X_group) >= frame_limit:\n",
    "        splitted_group = np.array_split(X_group, math.ceil(len(X_group) / frame_limit))\n",
    "        for g in splitted_group:\n",
    "            X_list.append(g.drop(['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success'], axis=1).to_numpy())\n",
    "            metadata.append({'filename': g.loc[g.index[0], 'filename'], 'face_id':g.loc[g.index[0], 'face_id']})\n",
    "            Y_list.append(Y_df.loc[g.loc[g.index[0], 'filename']].to_list())\n",
    "    else:\n",
    "        X_list.append(X_group.drop(['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success'], axis=1).to_numpy())\n",
    "        metadata.append({'filename': X_group.loc[X_group.index[0], 'filename'],  'face_id':X_group.loc[X_group.index[0], 'face_id']})\n",
    "        Y_list.append(Y_df.loc[g.loc[g.index[0], 'filename']].to_list())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ts = to_time_series_dataset(X_list)\n",
    "\n",
    "n_series = len(X_ts)\n",
    "distance_matrix = np.zeros(shape=(n_series, n_series))\n",
    "\n",
    "# Build distance matrix\n",
    "for i in range(n_series):\n",
    "    for j in range(n_series):\n",
    "        x = X_ts[i]\n",
    "        y = X_ts[j]\n",
    "        if i != j:\n",
    "            dist = soft_dtw(x, y)\n",
    "            distance_matrix[i, j] = dist"
   ]
  },
  {
   "source": [
    "https://scikit-learn.org/stable/modules/multiclass.html#classifierchain\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_ts, Y_list, test_size=.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "base_knn =  KNeighborsClassifier(n_neighbors=5)\n",
    "chains = [ClassifierChain(base_knn, order='random', random_state=i)\n",
    "          for i in range(7)]\n",
    "for model in chains:\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_chains = np.array([chain.predict(X_test) for chain in\n",
    "                          chains])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_accuracy_scores = [jaccard_score(Y_test, Y_pred_chain,\n",
    "                                      average='samples')\n",
    "                        for Y_pred_chain in Y_pred_chains]\n",
    "chain_f1_scores = [f1_score(Y_test, Y_pred_chain,  average='samples')\n",
    "                        for Y_pred_chain in Y_pred_chains]\n",
    "\n",
    "# multilabel_confusion_matrix(y_true, y_pred, samplewise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # kf = KFold(n_splits=5)\n",
    "    # kf.get_n_splits(X)\n",
    "\n",
    "    # for train_index, test_index in kf.split(X):\n",
    "\n",
    "    #     X_train, X_test = X.iloc[train_index, train_index], X.iloc[test_index, train_index]\n",
    "    #     Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    #     model = KNeighborsClassifier(n_neighbors=3, metric='precomputed')\n",
    "    #     model.fit(X_train, Y_train)\n",
    "    #     predictions = model.predict(X_test)\n",
    "\n",
    "    #     print(classification_report(Y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}