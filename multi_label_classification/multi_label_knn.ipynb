{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.validation import _check_large_sparse\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, jaccard_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_df(item_lists, unique_items):\n",
    "# Create empty dict\n",
    "    bool_dict = {}\n",
    "    \n",
    "    # Loop through all the tags\n",
    "    for i, item in enumerate(unique_items):\n",
    "        \n",
    "        # Apply boolean mask\n",
    "        bool_dict[item] = item_lists.apply(lambda x: 1 if item in x else 0)\n",
    "            \n",
    "    # Return the results as a dataframe\n",
    "    return pd.DataFrame(bool_dict)\n",
    "\n",
    "def to_1D(series):\n",
    "    return pd.Series([x for _list in series for x in _list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                none  furious  anger  annoyed  contempt  disgust  hatred\n",
       "filename                                                                \n",
       "na/vid_1.mp4       1        0      0        0         0        0       0\n",
       "na/vid_100.mp4     0        1      0        0         0        0       0\n",
       "na/vid_101.mp4     0        1      0        0         0        0       0\n",
       "na/vid_102.mp4     0        0      1        0         0        0       0\n",
       "na/vid_104.mp4     0        0      1        0         0        0       0\n",
       "...              ...      ...    ...      ...       ...      ...     ...\n",
       "na/vid_90.mp4      0        0      1        0         0        0       0\n",
       "na/vid_92.mp4      0        0      1        0         0        0       0\n",
       "na/vid_93.mp4      0        0      1        0         0        0       0\n",
       "na/vid_95.mp4      0        0      1        0         0        0       1\n",
       "na/vid_97.mp4      0        1      0        0         0        0       0\n",
       "\n",
       "[96 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>none</th>\n      <th>furious</th>\n      <th>anger</th>\n      <th>annoyed</th>\n      <th>contempt</th>\n      <th>disgust</th>\n      <th>hatred</th>\n    </tr>\n    <tr>\n      <th>filename</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>na/vid_1.mp4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>na/vid_100.mp4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>na/vid_101.mp4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>na/vid_102.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>na/vid_104.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>na/vid_90.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>na/vid_92.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>na/vid_93.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>na/vid_95.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>na/vid_97.mp4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>96 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "X_df = pd.read_csv('../new_data/NA/na_dataset.csv', index_col=None)\n",
    "Y_df = pd.read_csv('../new_data/NA/na_labels.csv', usecols=['filename', 'emotions'], index_col='filename')\n",
    "Y_df[\"emotions\"] = Y_df[\"emotions\"].apply(eval)\n",
    "unique_items = to_1D(Y_df[\"emotions\"]).unique()\n",
    "labels_expanded = boolean_df(Y_df['emotions'], unique_items)\n",
    "labels_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df['none']  = np.NaN\n",
    "X_df['furious']  = np.NaN\n",
    "X_df['anger']  = np.NaN\n",
    "X_df['annoyed']  = np.NaN\n",
    "X_df['contempt']  = np.NaN\n",
    "X_df['disgust']  = np.NaN\n",
    "X_df['hatred']  = np.NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in X_df.iterrows():\n",
    "    # print(index, row)\n",
    "    filename = X_df.iloc[index]['filename']\n",
    "    # print(labels_expanded.loc[filename]['none':'hatred'].to_list())\n",
    "    X_df.at[index,'none'] = labels_expanded.at[filename,'none']\n",
    "    X_df.at[index,'furious'] = labels_expanded.at[filename,'furious']\n",
    "    X_df.at[index,'anger'] = labels_expanded.at[filename,'anger']\n",
    "    X_df.at[index,'annoyed'] = labels_expanded.at[filename,'annoyed']\n",
    "    X_df.at[index,'contempt'] = labels_expanded.at[filename,'contempt']\n",
    "    X_df.at[index,'disgust'] = labels_expanded.at[filename,'disgust']\n",
    "    X_df.at[index,'hatred'] = labels_expanded.at[filename,'hatred']"
   ]
  },
  {
   "source": [
    "## Ablation Studies\n",
    "Run the cell below to remove columns for ablation studies and then run the training cell."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ablation cols\n",
    "# ablation_cols = ['AU01_r','AU02_r','AU04_r','AU05_r','AU06_r','AU07_r','AU09_r', 'AU10_r','AU12_r','AU14_r','AU15_r','AU17_r','AU20_r','AU23_r','AU25_r','AU26_r','AU45_r']\n",
    "ablation_cols = ['pose_Rx','pose_Ry','pose_Rz','gaze_angle_x','gaze_angle_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                filename  culture  frame  face_id  timestamp  confidence  \\\n",
       "0      persian/vid_1.mp4  persian      1        0      0.000        0.98   \n",
       "1      persian/vid_1.mp4  persian      2        0      0.033        0.98   \n",
       "2      persian/vid_1.mp4  persian      3        0      0.067        0.98   \n",
       "3      persian/vid_1.mp4  persian      4        0      0.100        0.98   \n",
       "4      persian/vid_1.mp4  persian      5        0      0.133        0.98   \n",
       "...                  ...      ...    ...      ...        ...         ...   \n",
       "9444  persian/vid_97.mp4  persian     35        0      1.360        0.98   \n",
       "9445  persian/vid_97.mp4  persian     36        0      1.400        0.98   \n",
       "9446  persian/vid_97.mp4  persian     37        0      1.440        0.98   \n",
       "9447  persian/vid_97.mp4  persian     38        0      1.480        0.98   \n",
       "9448  persian/vid_97.mp4  persian     39        0      1.520        0.98   \n",
       "\n",
       "      success  AU01_r  AU02_r  AU04_r  ...  AU25_r  AU26_r  AU45_r  none  \\\n",
       "0           1    0.94    0.24    0.43  ...    0.69     0.0    0.69   0.0   \n",
       "1           1    0.17    0.00    0.00  ...    1.39     0.0    1.21   0.0   \n",
       "2           1    0.10    0.00    0.00  ...    1.65     0.0    1.04   0.0   \n",
       "3           1    0.00    0.00    0.00  ...    1.46     0.0    0.83   0.0   \n",
       "4           1    0.00    0.00    0.00  ...    1.34     0.0    0.82   0.0   \n",
       "...       ...     ...     ...     ...  ...     ...     ...     ...   ...   \n",
       "9444        1    0.89    0.00    1.74  ...    0.00     0.0    0.67   0.0   \n",
       "9445        1    0.60    0.00    1.39  ...    0.00     0.0    0.62   0.0   \n",
       "9446        1    1.04    0.00    1.25  ...    0.00     0.0    0.66   0.0   \n",
       "9447        1    0.75    0.00    1.03  ...    0.00     0.0    0.65   0.0   \n",
       "9448        1    0.73    0.00    0.58  ...    0.00     0.0    0.65   0.0   \n",
       "\n",
       "      furious  anger  annoyed  contempt  disgust  hatred  \n",
       "0         0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "1         0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "2         0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "3         0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "4         0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "...       ...    ...      ...       ...      ...     ...  \n",
       "9444      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "9445      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "9446      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "9447      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "9448      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "\n",
       "[9449 rows x 31 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>culture</th>\n      <th>frame</th>\n      <th>face_id</th>\n      <th>timestamp</th>\n      <th>confidence</th>\n      <th>success</th>\n      <th>AU01_r</th>\n      <th>AU02_r</th>\n      <th>AU04_r</th>\n      <th>...</th>\n      <th>AU25_r</th>\n      <th>AU26_r</th>\n      <th>AU45_r</th>\n      <th>none</th>\n      <th>furious</th>\n      <th>anger</th>\n      <th>annoyed</th>\n      <th>contempt</th>\n      <th>disgust</th>\n      <th>hatred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.94</td>\n      <td>0.24</td>\n      <td>0.43</td>\n      <td>...</td>\n      <td>0.69</td>\n      <td>0.0</td>\n      <td>0.69</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.033</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.17</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>1.39</td>\n      <td>0.0</td>\n      <td>1.21</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.067</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.10</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>1.65</td>\n      <td>0.0</td>\n      <td>1.04</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.100</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>1.46</td>\n      <td>0.0</td>\n      <td>0.83</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0.133</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>1.34</td>\n      <td>0.0</td>\n      <td>0.82</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9444</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>35</td>\n      <td>0</td>\n      <td>1.360</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.89</td>\n      <td>0.00</td>\n      <td>1.74</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.67</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9445</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>36</td>\n      <td>0</td>\n      <td>1.400</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.60</td>\n      <td>0.00</td>\n      <td>1.39</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.62</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9446</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>37</td>\n      <td>0</td>\n      <td>1.440</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>1.04</td>\n      <td>0.00</td>\n      <td>1.25</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.66</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9447</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>38</td>\n      <td>0</td>\n      <td>1.480</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.75</td>\n      <td>0.00</td>\n      <td>1.03</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.65</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9448</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>39</td>\n      <td>0</td>\n      <td>1.520</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.73</td>\n      <td>0.00</td>\n      <td>0.58</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.65</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>9449 rows Ã— 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X_df = X_df.drop(columns=ablation_cols)\n",
    "X_df"
   ]
  },
  {
   "source": [
    "### Min-Max Scaling\n",
    "To limit the scale of features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = list (\n",
    "    set(X_df.columns.to_list()) - set(['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success', 'none', 'furious', 'anger', 'annoyed', 'contempt', 'disgust', 'hatred'])\n",
    ")\n",
    "scaler = MinMaxScaler()\n",
    "X_df[cols_to_scale] = scaler.fit_transform(X_df[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           filename         culture  frame  face_id  timestamp  confidence  \\\n",
       "6871  na/vid_97.mp4  north american     92        0      3.792        0.88   \n",
       "6872  na/vid_97.mp4  north american     93        0      3.833        0.88   \n",
       "6873  na/vid_97.mp4  north american     94        0      3.875        0.88   \n",
       "6874  na/vid_97.mp4  north american     95        0      3.917        0.88   \n",
       "6875  na/vid_97.mp4  north american     96        0      3.958        0.88   \n",
       "\n",
       "      success    AU01_r  AU02_r    AU04_r  ...   pose_Rz  gaze_angle_x  \\\n",
       "6871        1  0.176000     0.0  0.778098  ...  0.299421      0.241173   \n",
       "6872        1  0.000000     0.0  0.789625  ...  0.305689      0.247148   \n",
       "6873        1  0.021333     0.0  0.821326  ...  0.308100      0.248778   \n",
       "6874        1  0.000000     0.0  0.853026  ...  0.302797      0.239001   \n",
       "6875        1  0.000000     0.0  0.884726  ...  0.296528      0.240630   \n",
       "\n",
       "      gaze_angle_y  none  furious  anger  annoyed  contempt  disgust  hatred  \n",
       "6871      0.589481   0.0      1.0    0.0      0.0       0.0      0.0     0.0  \n",
       "6872      0.584368   0.0      1.0    0.0      0.0       0.0      0.0     0.0  \n",
       "6873      0.579985   0.0      1.0    0.0      0.0       0.0      0.0     0.0  \n",
       "6874      0.598977   0.0      1.0    0.0      0.0       0.0      0.0     0.0  \n",
       "6875      0.604091   0.0      1.0    0.0      0.0       0.0      0.0     0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>culture</th>\n      <th>frame</th>\n      <th>face_id</th>\n      <th>timestamp</th>\n      <th>confidence</th>\n      <th>success</th>\n      <th>AU01_r</th>\n      <th>AU02_r</th>\n      <th>AU04_r</th>\n      <th>...</th>\n      <th>pose_Rz</th>\n      <th>gaze_angle_x</th>\n      <th>gaze_angle_y</th>\n      <th>none</th>\n      <th>furious</th>\n      <th>anger</th>\n      <th>annoyed</th>\n      <th>contempt</th>\n      <th>disgust</th>\n      <th>hatred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6871</th>\n      <td>na/vid_97.mp4</td>\n      <td>north american</td>\n      <td>92</td>\n      <td>0</td>\n      <td>3.792</td>\n      <td>0.88</td>\n      <td>1</td>\n      <td>0.176000</td>\n      <td>0.0</td>\n      <td>0.778098</td>\n      <td>...</td>\n      <td>0.299421</td>\n      <td>0.241173</td>\n      <td>0.589481</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6872</th>\n      <td>na/vid_97.mp4</td>\n      <td>north american</td>\n      <td>93</td>\n      <td>0</td>\n      <td>3.833</td>\n      <td>0.88</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.789625</td>\n      <td>...</td>\n      <td>0.305689</td>\n      <td>0.247148</td>\n      <td>0.584368</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6873</th>\n      <td>na/vid_97.mp4</td>\n      <td>north american</td>\n      <td>94</td>\n      <td>0</td>\n      <td>3.875</td>\n      <td>0.88</td>\n      <td>1</td>\n      <td>0.021333</td>\n      <td>0.0</td>\n      <td>0.821326</td>\n      <td>...</td>\n      <td>0.308100</td>\n      <td>0.248778</td>\n      <td>0.579985</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6874</th>\n      <td>na/vid_97.mp4</td>\n      <td>north american</td>\n      <td>95</td>\n      <td>0</td>\n      <td>3.917</td>\n      <td>0.88</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.853026</td>\n      <td>...</td>\n      <td>0.302797</td>\n      <td>0.239001</td>\n      <td>0.598977</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6875</th>\n      <td>na/vid_97.mp4</td>\n      <td>north american</td>\n      <td>96</td>\n      <td>0</td>\n      <td>3.958</td>\n      <td>0.88</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.884726</td>\n      <td>...</td>\n      <td>0.296528</td>\n      <td>0.240630</td>\n      <td>0.604091</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 36 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "X_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting into train and test\n",
    "Randomly select 25% of videos apart for testing."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = X_df['filename'].unique()\n",
    "test_videos = pd.Series(videos).sample(frac=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       filename         culture  frame  face_id  timestamp  confidence  \\\n0  na/vid_1.mp4  north american      1        0      0.000        0.98   \n1  na/vid_1.mp4  north american      2        0      0.017        0.98   \n2  na/vid_1.mp4  north american      3        0      0.033        0.98   \n3  na/vid_1.mp4  north american      4        0      0.050        0.98   \n4  na/vid_1.mp4  north american      5        0      0.067        0.98   \n\n   success    AU01_r  AU02_r  AU04_r  ...   pose_Rz  gaze_angle_x  \\\n0        1  0.386667   0.372     0.0  ...  0.241562      0.527431   \n1        1  0.400000   0.396     0.0  ...  0.241080      0.524172   \n2        1  0.418667   0.396     0.0  ...  0.240598      0.523628   \n3        1  0.416000   0.398     0.0  ...  0.240598      0.523628   \n4        1  0.373333   0.388     0.0  ...  0.235776      0.519826   \n\n   gaze_angle_y  none  furious  anger  annoyed  contempt  disgust  hatred  \n0      0.655223   1.0      0.0    0.0      0.0       0.0      0.0     0.0  \n1      0.650840   1.0      0.0    0.0      0.0       0.0      0.0     0.0  \n2      0.651570   1.0      0.0    0.0      0.0       0.0      0.0     0.0  \n3      0.651570   1.0      0.0    0.0      0.0       0.0      0.0     0.0  \n4      0.657414   1.0      0.0    0.0      0.0       0.0      0.0     0.0  \n\n[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "metadata_cols = ['frame', 'face_id', 'culture', 'filename', 'timestamp']\n",
    "label_cols = ['none', 'furious', 'anger', 'annoyed', 'contempt', 'disgust', 'hatred']\n",
    "\n",
    "print(X_df.head())\n",
    "\n",
    "# test_videos = ['persian/vid_40.mp4', 'persian/vid_66.mp4', 'persian/vid_18.mp4', 'persian/vid_96.mp4', 'persian/vid_65.mp4', 'persian/vid_51.mp4', 'persian/vid_85.mp4', 'persian/vid_87.mp4', 'persian/vid_27.mp4','persian/vid_21.mp4', 'persian/vid_4.mp4', 'persian/vid_61.mp4', 'persian/vid_12.mp4', 'persian/vid_81.mp4','persian/vid_56.mp4', 'persian/vid_55.mp4',  'persian/vid_38.mp4', 'persian/vid_8.mp4',  'persian/vid_91.mp4', 'persian/vid_22.mp4', 'persian/vid_36.mp4', 'persian/vid_7.mp4']\n",
    "# test_videos = ['na/vid_6.mp4', 'na/vid_19.mp4', 'na/vid_43.mp4', 'na/vid_25.mp4', 'na/vid_23.mp4', 'na/vid_10_1.mp4', 'na/vid_72.mp4', 'na/vid_34.mp4', 'na/vid_90.mp4', 'na/vid_92.mp4', 'na/vid_39.mp4', 'na/vid_30.mp4', 'na/vid_3.mp4', 'na/vid_33.mp4', 'na/vid_4.mp4', 'na/vid_31.mp4', 'na/vid_53.mp4', 'na/vid_52.mp4', 'na/vid_55.mp4', 'na/vid_59.mp4', 'na/vid_22.mp4', 'na/vid_11.mp4', 'na/vid_79.mp4', 'na/vid_54.mp4', 'na/vid_87.mp4', 'na/vid_63.mp4', 'na/vid_12.mp4', 'na/vid_10_2.mp4', 'na/vid_97.mp4', 'na/vid_70.mp4', 'na/vid_42.mp4', 'na/vid_49.mp4', 'na/vid_77.mp4']\n",
    "train_videos = np.array(list(set(videos) - set(test_videos)))\n",
    "test_df = X_df[X_df['filename'].isin(test_videos)]\n",
    "metadata_test = test_df[metadata_cols]\n",
    "metadata_test.reset_index(inplace=True)\n",
    "y_test = test_df[label_cols].values\n",
    "X_test = test_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success'] + label_cols).values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2265"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "len(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[800:805,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_test.iloc[800:805]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Training with Cross-validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Classifier Chain\n",
    "Choose one of the classifiers for CC: base_knn, base_rf"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1-th split: train: 56, test: 14\n",
      "['na/vid_38.mp4' 'na/vid_77.mp4' 'na/vid_73.mp4' 'na/vid_15.mp4'\n",
      " 'na/vid_65.mp4' 'na/vid_46.mp4' 'na/vid_22.mp4' 'na/vid_17.mp4'\n",
      " 'na/vid_18.mp4' 'na/vid_81.mp4' 'na/vid_16.mp4' 'na/vid_29.mp4'\n",
      " 'na/vid_72.mp4' 'na/vid_21.mp4' 'na/vid_100.mp4' 'na/vid_62.mp4'\n",
      " 'na/vid_43.mp4' 'na/vid_63.mp4' 'na/vid_101.mp4' 'na/vid_66.mp4'\n",
      " 'na/vid_9.mp4' 'na/vid_49.mp4' 'na/vid_85.mp4' 'na/vid_104.mp4'\n",
      " 'na/vid_45.mp4' 'na/vid_1.mp4' 'na/vid_57.mp4' 'na/vid_39.mp4'\n",
      " 'na/vid_27.mp4' 'na/vid_84.mp4' 'na/vid_53.mp4' 'na/vid_44.mp4'\n",
      " 'na/vid_35.mp4' 'na/vid_88.mp4' 'na/vid_20.mp4' 'na/vid_61.mp4'\n",
      " 'na/vid_78.mp4' 'na/vid_37.mp4' 'na/vid_47.mp4' 'na/vid_75.mp4'\n",
      " 'na/vid_82.mp4' 'na/vid_12.mp4' 'na/vid_11.mp4' 'na/vid_2.mp4'\n",
      " 'na/vid_74.mp4' 'na/vid_33.mp4' 'na/vid_69.mp4' 'na/vid_97.mp4'\n",
      " 'na/vid_36.mp4' 'na/vid_23.mp4' 'na/vid_30.mp4' 'na/vid_8.mp4'\n",
      " 'na/vid_51.mp4' 'na/vid_89.mp4' 'na/vid_80.mp4' 'na/vid_26.mp4']\n",
      "Training+validation data size:  4246\n",
      "Training data size:  4246\n",
      "Validation data size:  1040\n",
      "One-vs-Rest validation Jaccard score: 0.07900641025641025\n",
      "One-vs-Rest validation Hamming loss:  0.1967032967032967\n",
      "One-vs-Rest test Jaccard score:  0.30020964360587\n",
      "One-vs-Rest test Hamming loss:  0.1641509433962264\n",
      "CC Validation Jaccard Score:\n",
      "  0.2641025641025641\n",
      "CC Validation Hamming Loss:\n",
      "  0.20824175824175825\n",
      "CC Test Jaccard Score: \n",
      "  0.3682389937106918\n",
      "CC Test Hamming Loss:\n",
      "  0.19155435759209344\n",
      "(24, 7)\n",
      "(24, 7)\n",
      "2-th split: train: 56, test: 14\n",
      "['na/vid_38.mp4' 'na/vid_77.mp4' 'na/vid_25.mp4' 'na/vid_15.mp4'\n",
      " 'na/vid_65.mp4' 'na/vid_46.mp4' 'na/vid_22.mp4' 'na/vid_17.mp4'\n",
      " 'na/vid_18.mp4' 'na/vid_81.mp4' 'na/vid_16.mp4' 'na/vid_29.mp4'\n",
      " 'na/vid_72.mp4' 'na/vid_21.mp4' 'na/vid_100.mp4' 'na/vid_62.mp4'\n",
      " 'na/vid_43.mp4' 'na/vid_63.mp4' 'na/vid_101.mp4' 'na/vid_66.mp4'\n",
      " 'na/vid_49.mp4' 'na/vid_85.mp4' 'na/vid_104.mp4' 'na/vid_45.mp4'\n",
      " 'na/vid_5.mp4' 'na/vid_59.mp4' 'na/vid_1.mp4' 'na/vid_57.mp4'\n",
      " 'na/vid_39.mp4' 'na/vid_19.mp4' 'na/vid_27.mp4' 'na/vid_31.mp4'\n",
      " 'na/vid_67.mp4' 'na/vid_44.mp4' 'na/vid_7.mp4' 'na/vid_88.mp4'\n",
      " 'na/vid_20.mp4' 'na/vid_61.mp4' 'na/vid_37.mp4' 'na/vid_47.mp4'\n",
      " 'na/vid_75.mp4' 'na/vid_95.mp4' 'na/vid_58.mp4' 'na/vid_12.mp4'\n",
      " 'na/vid_3.mp4' 'na/vid_4.mp4' 'na/vid_33.mp4' 'na/vid_70.mp4'\n",
      " 'na/vid_23.mp4' 'na/vid_8.mp4' 'na/vid_51.mp4' 'na/vid_76.mp4'\n",
      " 'na/vid_42.mp4' 'na/vid_89.mp4' 'na/vid_80.mp4' 'na/vid_26.mp4']\n",
      "Training+validation data size:  4097\n",
      "Training data size:  4097\n",
      "Validation data size:  1189\n",
      "One-vs-Rest validation Jaccard score: 0.23521166246145223\n",
      "One-vs-Rest validation Hamming loss:  0.16232127838519764\n",
      "One-vs-Rest test Jaccard score:  0.38207547169811323\n",
      "One-vs-Rest test Hamming loss:  0.15795148247978436\n",
      "CC Validation Jaccard Score:\n",
      "  0.29058031959629943\n",
      "CC Validation Hamming Loss:\n",
      "  0.2043734230445753\n",
      "CC Test Jaccard Score: \n",
      "  0.44203354297693925\n",
      "CC Test Hamming Loss:\n",
      "  0.17196765498652292\n",
      "(24, 7)\n",
      "(24, 7)\n",
      "3-th split: train: 56, test: 14\n",
      "['na/vid_77.mp4' 'na/vid_25.mp4' 'na/vid_73.mp4' 'na/vid_15.mp4'\n",
      " 'na/vid_65.mp4' 'na/vid_46.mp4' 'na/vid_22.mp4' 'na/vid_18.mp4'\n",
      " 'na/vid_16.mp4' 'na/vid_29.mp4' 'na/vid_21.mp4' 'na/vid_62.mp4'\n",
      " 'na/vid_63.mp4' 'na/vid_66.mp4' 'na/vid_9.mp4' 'na/vid_85.mp4'\n",
      " 'na/vid_45.mp4' 'na/vid_5.mp4' 'na/vid_59.mp4' 'na/vid_1.mp4'\n",
      " 'na/vid_57.mp4' 'na/vid_39.mp4' 'na/vid_19.mp4' 'na/vid_27.mp4'\n",
      " 'na/vid_84.mp4' 'na/vid_53.mp4' 'na/vid_31.mp4' 'na/vid_67.mp4'\n",
      " 'na/vid_44.mp4' 'na/vid_35.mp4' 'na/vid_7.mp4' 'na/vid_20.mp4'\n",
      " 'na/vid_61.mp4' 'na/vid_78.mp4' 'na/vid_47.mp4' 'na/vid_75.mp4'\n",
      " 'na/vid_82.mp4' 'na/vid_95.mp4' 'na/vid_58.mp4' 'na/vid_12.mp4'\n",
      " 'na/vid_11.mp4' 'na/vid_2.mp4' 'na/vid_3.mp4' 'na/vid_4.mp4'\n",
      " 'na/vid_74.mp4' 'na/vid_33.mp4' 'na/vid_69.mp4' 'na/vid_97.mp4'\n",
      " 'na/vid_36.mp4' 'na/vid_70.mp4' 'na/vid_30.mp4' 'na/vid_51.mp4'\n",
      " 'na/vid_76.mp4' 'na/vid_42.mp4' 'na/vid_80.mp4' 'na/vid_26.mp4']\n",
      "Training+validation data size:  4426\n",
      "Training data size:  4426\n",
      "Validation data size:  860\n",
      "One-vs-Rest validation Jaccard score: 0.24806201550387594\n",
      "One-vs-Rest validation Hamming loss:  0.2004983388704319\n",
      "One-vs-Rest test Jaccard score:  0.37484276729559746\n",
      "One-vs-Rest test Hamming loss:  0.16298292902066486\n",
      "CC Validation Jaccard Score:\n",
      "  0.30019379844961236\n",
      "CC Validation Hamming Loss:\n",
      "  0.2227574750830565\n",
      "CC Test Jaccard Score: \n",
      "  0.39570230607966456\n",
      "CC Test Hamming Loss:\n",
      "  0.1778975741239892\n",
      "(24, 7)\n",
      "(24, 7)\n",
      "4-th split: train: 56, test: 14\n",
      "['na/vid_38.mp4' 'na/vid_77.mp4' 'na/vid_25.mp4' 'na/vid_73.mp4'\n",
      " 'na/vid_65.mp4' 'na/vid_46.mp4' 'na/vid_22.mp4' 'na/vid_17.mp4'\n",
      " 'na/vid_18.mp4' 'na/vid_81.mp4' 'na/vid_29.mp4' 'na/vid_72.mp4'\n",
      " 'na/vid_100.mp4' 'na/vid_62.mp4' 'na/vid_43.mp4' 'na/vid_101.mp4'\n",
      " 'na/vid_66.mp4' 'na/vid_9.mp4' 'na/vid_49.mp4' 'na/vid_104.mp4'\n",
      " 'na/vid_45.mp4' 'na/vid_5.mp4' 'na/vid_59.mp4' 'na/vid_19.mp4'\n",
      " 'na/vid_84.mp4' 'na/vid_53.mp4' 'na/vid_31.mp4' 'na/vid_67.mp4'\n",
      " 'na/vid_44.mp4' 'na/vid_35.mp4' 'na/vid_7.mp4' 'na/vid_88.mp4'\n",
      " 'na/vid_78.mp4' 'na/vid_37.mp4' 'na/vid_47.mp4' 'na/vid_82.mp4'\n",
      " 'na/vid_95.mp4' 'na/vid_58.mp4' 'na/vid_12.mp4' 'na/vid_11.mp4'\n",
      " 'na/vid_2.mp4' 'na/vid_3.mp4' 'na/vid_4.mp4' 'na/vid_74.mp4'\n",
      " 'na/vid_69.mp4' 'na/vid_97.mp4' 'na/vid_36.mp4' 'na/vid_70.mp4'\n",
      " 'na/vid_23.mp4' 'na/vid_30.mp4' 'na/vid_8.mp4' 'na/vid_51.mp4'\n",
      " 'na/vid_76.mp4' 'na/vid_42.mp4' 'na/vid_89.mp4' 'na/vid_80.mp4']\n",
      "Training+validation data size:  4056\n",
      "Training data size:  4056\n",
      "Validation data size:  1230\n",
      "One-vs-Rest validation Jaccard score: 0.1149051490514905\n",
      "One-vs-Rest validation Hamming loss:  0.21300813008130082\n",
      "One-vs-Rest test Jaccard score:  0.3382599580712788\n",
      "One-vs-Rest test Hamming loss:  0.17430368373764601\n",
      "CC Validation Jaccard Score:\n",
      "  0.16043360433604334\n",
      "CC Validation Hamming Loss:\n",
      "  0.24390243902439024\n",
      "CC Test Jaccard Score: \n",
      "  0.37484276729559746\n",
      "CC Test Hamming Loss:\n",
      "  0.19433962264150945\n",
      "(24, 7)\n",
      "(24, 7)\n",
      "5-th split: train: 56, test: 14\n",
      "['na/vid_38.mp4' 'na/vid_25.mp4' 'na/vid_73.mp4' 'na/vid_15.mp4'\n",
      " 'na/vid_17.mp4' 'na/vid_81.mp4' 'na/vid_16.mp4' 'na/vid_72.mp4'\n",
      " 'na/vid_21.mp4' 'na/vid_100.mp4' 'na/vid_43.mp4' 'na/vid_63.mp4'\n",
      " 'na/vid_101.mp4' 'na/vid_9.mp4' 'na/vid_49.mp4' 'na/vid_85.mp4'\n",
      " 'na/vid_104.mp4' 'na/vid_5.mp4' 'na/vid_59.mp4' 'na/vid_1.mp4'\n",
      " 'na/vid_57.mp4' 'na/vid_39.mp4' 'na/vid_19.mp4' 'na/vid_27.mp4'\n",
      " 'na/vid_84.mp4' 'na/vid_53.mp4' 'na/vid_31.mp4' 'na/vid_67.mp4'\n",
      " 'na/vid_35.mp4' 'na/vid_7.mp4' 'na/vid_88.mp4' 'na/vid_20.mp4'\n",
      " 'na/vid_61.mp4' 'na/vid_78.mp4' 'na/vid_37.mp4' 'na/vid_75.mp4'\n",
      " 'na/vid_82.mp4' 'na/vid_95.mp4' 'na/vid_58.mp4' 'na/vid_11.mp4'\n",
      " 'na/vid_2.mp4' 'na/vid_3.mp4' 'na/vid_4.mp4' 'na/vid_74.mp4'\n",
      " 'na/vid_33.mp4' 'na/vid_69.mp4' 'na/vid_97.mp4' 'na/vid_36.mp4'\n",
      " 'na/vid_70.mp4' 'na/vid_23.mp4' 'na/vid_30.mp4' 'na/vid_8.mp4'\n",
      " 'na/vid_76.mp4' 'na/vid_42.mp4' 'na/vid_89.mp4' 'na/vid_26.mp4']\n",
      "Training+validation data size:  4319\n",
      "Training data size:  4319\n",
      "Validation data size:  967\n",
      "One-vs-Rest validation Jaccard score: 0.1563254050327473\n",
      "One-vs-Rest validation Hamming loss:  0.20992761116856257\n",
      "One-vs-Rest test Jaccard score:  0.41352201257861637\n",
      "One-vs-Rest test Hamming loss:  0.1508535489667565\n",
      "CC Validation Jaccard Score:\n",
      "  0.3150637711134091\n",
      "CC Validation Hamming Loss:\n",
      "  0.19249519869995568\n",
      "CC Test Jaccard Score: \n",
      "  0.45303983228511524\n",
      "CC Test Hamming Loss:\n",
      "  0.16810422282120396\n",
      "(24, 7)\n",
      "(24, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "kfold = KFold(5, True, 1)\n",
    "frames_mean_hm_test = []\n",
    "frames_mean_jac_test = []\n",
    "videos_mean_jac_test = []\n",
    "videos_mean_hm_test = []\n",
    "# metadata_test.reset_index(inplace=True)\n",
    "\n",
    "col_indices = {i:label for (i,label) in enumerate(label_cols)}\n",
    "\n",
    "splits = kfold.split(train_videos)\n",
    "for (i, (train, test)) in enumerate(splits):\n",
    "    # print(videos[train])\n",
    "    # print(videos[test])\n",
    "    print('%d-th split: train: %d, test: %d' % (i+1, len(train_videos[train]), len(train_videos[test])))\n",
    "    train_df = X_df[X_df['filename'].isin(train_videos[train])]\n",
    "    print(train_videos[train])\n",
    "    train_metadata = train_df[metadata_cols]\n",
    "    print('Training+validation data size: ', train_df.shape[0])\n",
    "    y_train = train_df[label_cols].values\n",
    "    X_train = train_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success'] + label_cols).values\n",
    "    valid_df = X_df[X_df['filename'].isin(train_videos[test])]\n",
    "    y_valid = valid_df[label_cols].values\n",
    "    X_valid = valid_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success'] + label_cols).values\n",
    "    # X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "    print('Training data size: ', X_train.shape[0])\n",
    "    print('Validation data size: ', X_valid.shape[0])\n",
    "    base_knn =  KNeighborsClassifier(n_neighbors=5,)\n",
    "    base_xgb = XGBClassifier(objective=\"binary:logistic\", learning_rate=0.2, eval_metric='logloss')\n",
    "    base_rf = RandomForestClassifier()\n",
    "\n",
    "    ovr = MultiOutputClassifier(XGBClassifier(objective=\"binary:logistic\", learning_rate=0.2, eval_metric='auc'))\n",
    "    ovr.fit(X_train, y_train)\n",
    "    valid_pred_ovr = ovr.predict(X_valid)\n",
    "    ovr_jaccard_score = jaccard_score(y_valid, valid_pred_ovr, average='samples')\n",
    "    ovr_ham_loss = metrics.hamming_loss(y_valid, valid_pred_ovr)\n",
    "    print(\"One-vs-Rest validation Jaccard score:\" , ovr_jaccard_score)\n",
    "    print(\"One-vs-Rest validation Hamming loss: \" , ovr_ham_loss)\n",
    "\n",
    "   \n",
    "    Y_pred_ovr = ovr.predict(X_test)\n",
    "    a = jaccard_score(y_test, Y_pred_ovr, average='samples')\n",
    "    b = metrics.hamming_loss(y_test, Y_pred_ovr)\n",
    "    # print(Y_pred_ovr[800:805,:])\n",
    "    # print(y_test[800:805,:])\n",
    "\n",
    "    print(\"One-vs-Rest test Jaccard score: \", a)\n",
    "    print(\"One-vs-Rest test Hamming loss: \" , b)\n",
    "    # set order from higher arousal emotions to lower arousal.\n",
    "    order=[1, 6, 2, 5, 4, 3, 0]\n",
    "    chains = [ClassifierChain(base_xgb, order='random', random_state=0) for i in range(7)]\n",
    "    best_model_index = 0\n",
    "    best_jac = 0            \n",
    "    for j, model in enumerate(chains):\n",
    "        model.fit(X_train, y_train)\n",
    "        valid_pred = model.predict(X_valid)\n",
    "        val_score =jaccard_score(y_valid, valid_pred, average='samples')\n",
    "        if val_score > best_jac:\n",
    "            best_model_index = j\n",
    "            best_jac = val_score\n",
    "            \n",
    "        \n",
    "    # predict on validation data\n",
    "    valid_pred_chains = chains[best_model_index].predict(X_valid)\n",
    "    chain_jaccard_scores = jaccard_score(y_valid, valid_pred_chains >= .5,\n",
    "                                    average='samples')\n",
    "\n",
    "    \n",
    "    print(\"CC Validation Jaccard Score:\\n \", chain_jaccard_scores)\n",
    "\n",
    "    chain_hamming_loss =metrics.hamming_loss(y_valid, valid_pred_chains >= .5)\n",
    "                \n",
    "    print(\"CC Validation Hamming Loss:\\n \", chain_hamming_loss)\n",
    "\n",
    "    # test on test data\n",
    "    Y_pred_chains = chains[best_model_index].predict(X_test)\n",
    "    chain_jaccard_scores = jaccard_score(y_test, Y_pred_chains >= .5,\n",
    "                                    average='samples')\n",
    "                    \n",
    "\n",
    "    # chain01_scores = [metrics.zero_one_loss(y_test, Y_pred_chain) for Y_pred_chain in Y_pred_chains]\n",
    "\n",
    "    frames_mean_jac_test.append(np.mean(chain_jaccard_scores))\n",
    "    print(\"CC Test Jaccard Score: \\n \", chain_jaccard_scores)\n",
    "\n",
    "    chain_hamming_loss = metrics.hamming_loss(y_test, Y_pred_chains) \n",
    "                \n",
    "    frames_mean_hm_test.append(np.mean(chain_hamming_loss))\n",
    "    print(\"CC Test Hamming Loss:\\n \", chain_hamming_loss)\n",
    "    ## voting predicted labels\n",
    "    # test_result_df = pd.DataFrame(columns=metadata_cols, data=metadata_test.values)\n",
    "    # test_result_df.update(metadata_test)\n",
    "    temp_df = pd.DataFrame(data=Y_pred_chains, columns=label_cols)\n",
    "    test_result_df = pd.concat([metadata_test, temp_df], axis=1)\n",
    "    video_groups = test_result_df.groupby('filename')[label_cols].sum()\n",
    "    ground_truth_video_labels = []\n",
    "    for v in video_groups.index.to_list():\n",
    "        # number of 1s in ground truth labels\n",
    "        ground_truth_video_labels.append(test_df[test_df['filename'] == v].iloc[0][label_cols])\n",
    "        \n",
    "        num_1s = test_df[test_df['filename'] == v].iloc[0][label_cols].sum()\n",
    "        num_1s = int(num_1s)\n",
    "        # ##### TODO: Bug is somewhere here:\n",
    "        a = np.argsort(video_groups.loc[v].values)\n",
    "        for i in range(len(a) - 1, len(a) - num_1s - 1, -1):\n",
    "            video_groups.loc[v][a[i]] = 1\n",
    "        for i in range(0, len(a) - num_1s):\n",
    "            video_groups.loc[v][a[i]] = 0\n",
    "        # print(\"          &&&&&&&&&&&&&&&&            \")\n",
    "    print(np.array(ground_truth_video_labels,  dtype=int).shape)\n",
    "    print(video_groups.values.shape)\n",
    "\n",
    "    j = metrics.jaccard_score(np.array(ground_truth_video_labels,  dtype=int), video_groups.values, average='samples')\n",
    "    h = metrics.hamming_loss(np.array(ground_truth_video_labels,  dtype=int), video_groups.values)\n",
    "    videos_mean_jac_test.append(j)\n",
    "    videos_mean_hm_test.append(h)\n"
   ]
  },
  {
   "source": [
    "## Classification Report"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------- Frame-level F1 -----------------\n              precision    recall  f1-score   support\n\n        none       0.44      0.73      0.55        99\n     furious       0.29      0.59      0.39        54\n       anger       0.73      0.37      0.49       416\n     annoyed       0.58      0.65      0.61       658\n    contempt       0.24      0.30      0.27       204\n     disgust       0.91      0.25      0.39       558\n      hatred       0.00      0.00      0.00         0\n\n   micro avg       0.54      0.45      0.49      1989\n   macro avg       0.46      0.41      0.39      1989\nweighted avg       0.65      0.45      0.48      1989\n samples avg       0.52      0.46      0.48      1989\n\n------------------- Video-level F1 -----------------\n              precision    recall  f1-score   support\n\n        none       0.50      0.50      0.50         2\n     furious       0.50      1.00      0.67         1\n       anger       0.75      0.38      0.50         8\n     annoyed       0.45      0.83      0.59         6\n    contempt       0.17      0.25      0.20         4\n     disgust       1.00      0.38      0.55         8\n      hatred       0.00      0.00      0.00         0\n\n   micro avg       0.48      0.48      0.48        29\n   macro avg       0.48      0.48      0.43        29\nweighted avg       0.65      0.48      0.50        29\n samples avg       0.44      0.44      0.44        29\n\n"
     ]
    }
   ],
   "source": [
    "print('------------------- Frame-level F1 -----------------')\n",
    "print(metrics.classification_report(y_test, Y_pred_chains, target_names=label_cols))\n",
    "print('------------------- Video-level F1 -----------------')\n",
    "print(metrics.classification_report(np.array(ground_truth_video_labels,  dtype=int),  video_groups.values, target_names=label_cols))"
   ]
  },
  {
   "source": [
    "Print average of metrics\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F-jac:  0.40677148846960165\nV-jac:  0.40555555555555556\nF-ham:  0.1807726864330638\nV-ham:  0.1880952380952381\n"
     ]
    }
   ],
   "source": [
    "print(\"F-jac: \", np.mean(frames_mean_jac_test))\n",
    "print(\"V-jac: \", np.mean(videos_mean_jac_test))\n",
    "print(\"F-ham: \", np.mean(frames_mean_hm_test))\n",
    "print(\"V-ham: \", np.mean(videos_mean_hm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.40277777777777773,\n",
       " 0.4583333333333333,\n",
       " 0.3611111111111111,\n",
       " 0.38888888888888884,\n",
       " 0.4166666666666667]"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "videos_mean_jac_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['na/vid_52.mp4', 'na/vid_13.mp4', 'na/vid_54.mp4', 'na/vid_92.mp4', 'na/vid_48.mp4', 'na/vid_93.mp4', 'na/vid_6.mp4', 'na/vid_50.mp4', 'na/vid_14.mp4', 'na/vid_10_1.mp4', 'na/vid_34.mp4', 'na/vid_86.mp4', 'na/vid_83.mp4', 'na/vid_90.mp4', 'na/vid_55.mp4', 'na/vid_60.mp4', 'na/vid_24.mp4', 'na/vid_10_3.mp4', 'na/vid_10_2.mp4', 'na/vid_87.mp4', 'na/vid_32.mp4', 'na/vid_79.mp4', 'na/vid_68.mp4', 'na/vid_56.mp4']\n"
     ]
    }
   ],
   "source": [
    "print(test_videos.to_list())"
   ]
  },
  {
   "source": [
    "## Confused frames\n",
    "The cell below finds frames that are misclassified"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# Confusions\n",
    "confused = 0\n",
    "for i,_ in enumerate(y_test):\n",
    "    if np.subtract(y_test[i], test_result_df.iloc[i][label_cols].to_numpy(dtype=int)).sum() != 0.0:\n",
    "        confused += 1\n",
    "        print(metadata_test.iloc[i], \"------- Actual: \", y_test[i], \" ----- pred: \", Y_pred_chains[i])\n",
    "print(\"confused: \", confused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F-jac:  0.19309672929714683\nV-jac:  0.13444444444444445\nF-ham:  0.28911422606620935\nV-ham:  0.2952380952380952\n"
     ]
    }
   ],
   "source": [
    "print(\"F-jac: \", np.mean(frames_mean_jac_test))\n",
    "print(\"V-jac: \", np.mean(videos_mean_jac_test))\n",
    "print(\"F-ham: \", np.mean(frames_mean_hm_test))\n",
    "print(\"V-ham: \", np.mean(videos_mean_hm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.grid(True)\n",
    "ax.set_title('CC Jaccard Score')\n",
    "ax.set_xticks(range(0,7))\n",
    "ax.set_xticklabels(range(0,7))\n",
    "ax.set_ylabel('Jaccard Similarity Score')\n",
    "ax.set_ylim([0.0, 1.1])\n",
    "\n",
    "plt.plot(frames_mean_jac_test, label='Frames Jaccard Score', color='blue')\n",
    "plt.plot(videos_mean_jac_test, label='Video Jaccard Score', color='green')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.grid(True)\n",
    "ax.set_title('CC Hamming Loss')\n",
    "ax.set_xticks(range(0,7))\n",
    "ax.set_xticklabels(range(0,7))\n",
    "ax.set_ylabel('Hamming Distance Loss')\n",
    "ax.set_ylim([0.00, .1])\n",
    "# ax.legend(('Frames Hamming Loss','Video Hamming Loss' ))\n",
    "plt.plot(frames_mean_hm_test, label='Frames Hamming Loss', color='red')\n",
    "plt.plot(videos_mean_hm_test, label='Video Hamming Loss', color='green')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### ML KNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN, MLTSVM\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "## MLTSVM is not compatible with later versions of numpy\n",
    "\n",
    "kfold = KFold(5, True, 1)\n",
    "frames_mean_hm_test = []\n",
    "frames_mean_jac_test = []\n",
    "videos_mean_jac_test = []\n",
    "videos_mean_hm_test = []\n",
    "col_indices = {i:label for (i,label) in enumerate(label_cols)}\n",
    "\n",
    "splits = kfold.split(train_videos)\n",
    "for (i, (train, test)) in enumerate(splits):\n",
    "    print('%d-th split: train: %d, validation: %d' % (i+1, len(videos[train]), len(videos[test])))\n",
    "    train_df = X_df[X_df['filename'].isin(train_videos[train])]\n",
    "    train_metadata = train_df[metadata_cols]\n",
    "    print('Training+validation data size: ', train_df.shape[0])\n",
    "    y_train = train_df[label_cols].values\n",
    "    X_train = train_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success'] + label_cols).values\n",
    "    valid_df = X_df[X_df['filename'].isin(train_videos[test])]\n",
    "    y_valid = valid_df[label_cols].values\n",
    "    X_valid = valid_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success']+ label_cols).values\n",
    "    \n",
    "    print('Training data size: ', X_train.shape[0])\n",
    "    print('Validation data size: ', X_valid.shape[0])\n",
    "    classifier = MLkNN(k=5)\n",
    "    # classifier = MLTSVM(c_k = 2**-1)\n",
    "    prediction = classifier.fit(X_train, y_train).predict(X_valid)\n",
    "\n",
    "    # Predicting on validation set\n",
    "    print(\"Validation Hamming Loss:\\n \", metrics.hamming_loss(y_valid, prediction))\n",
    "\n",
    "    # Predicting on test set\n",
    "    y_test_pred = classifier.predict(X_test)\n",
    "    hm_loss = metrics.hamming_loss(y_test, y_test_pred)\n",
    "    frames_mean_hm_test.append(hm_loss)\n",
    "    print(\"Test Hamming Loss:\\n \", hm_loss)\n",
    "    jac_score = jaccard_score(y_test, y_test_pred,  average='samples')\n",
    "    frames_mean_jac_test.append(jac_score)\n",
    "    print(\"Test Jaccard Score:\\n \", jac_score)\n",
    "\n",
    "    # building test dataframe to vote labels\n",
    "    # test_result_df = pd.DataFrame(columns=metadata_cols, data=metadata_test.values)\n",
    "    # test_result_df.update(metadata_test)\n",
    "    # print(\"^^^^^^^^\", y_test_pred.toarray().shape)\n",
    "    temp_df = pd.DataFrame(data=y_test_pred.toarray(), columns=label_cols)\n",
    "    test_result_df = pd.concat([metadata_test, temp_df], axis=1)\n",
    "    \n",
    "    # print(test_result_df.head())\n",
    "    video_groups = test_result_df.groupby('filename')[label_cols].apply(lambda x : x.astype(int).sum())\n",
    "    # for name, group in video_groups:\n",
    "    #     print(name)\n",
    "    #     print(group)\n",
    "    #     print(\"\\n\") \n",
    "    ground_truth_video_labels = []\n",
    "    for v in video_groups.index.to_list():\n",
    "        # number of 1s in ground truth labels\n",
    "        ground_truth_video_labels.append(test_df[test_df['filename'] == v].iloc[0][label_cols])\n",
    "        num_1s = test_df[test_df['filename'] == v].iloc[0][label_cols].sum()\n",
    "        num_1s = int(num_1s)\n",
    "        a = np.argsort(video_groups.loc[v].values)\n",
    "        for i in range(len(a) - 1, len(a) - num_1s - 1, -1):\n",
    "            video_groups.loc[v][a[i]] = 1\n",
    "        for i in range(0, len(a) - num_1s):\n",
    "            video_groups.loc[v][a[i]] = 0\n",
    "\n",
    "    j = metrics.jaccard_score(np.array(ground_truth_video_labels,  dtype=int), video_groups.values, average='samples')\n",
    "    h = metrics.hamming_loss(np.array(ground_truth_video_labels,  dtype=int), video_groups.values)\n",
    "    videos_mean_jac_test.append(j)\n",
    "    videos_mean_hm_test.append(h)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.grid(True)\n",
    "ax.set_title('MLKNN Jaccard Score')\n",
    "ax.set_xticks(range(0,7))\n",
    "ax.set_xticklabels(range(0,7))\n",
    "ax.set_ylabel('Jaccard Similarity Score')\n",
    "ax.set_ylim([0.00, 1.0])\n",
    "\n",
    "plt.plot(frames_mean_jac_test, label='Frames Jaccard Score', color='blue')\n",
    "plt.plot(videos_mean_jac_test, label='Video Jaccard Score', color='green')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F-jac: \", np.mean(frames_mean_jac_test))\n",
    "print(\"V-jac: \", np.mean(videos_mean_jac_test))\n",
    "print(\"F-ham: \", np.mean(frames_mean_hm_test))\n",
    "print(\"V-ham: \", np.mean(videos_mean_hm_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_mean_jac_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.grid(True)\n",
    "ax.set_title('MLKNN Hamming Loss')\n",
    "ax.set_xticks(range(0,7))\n",
    "ax.set_xticklabels(range(0,7))\n",
    "ax.set_ylabel('Hamming Distance Loss')\n",
    "ax.set_ylim([0.00, 1.0])\n",
    "# ax.legend(('Frames Hamming Loss','Video Hamming Loss' ))\n",
    "plt.plot(frames_mean_hm_test, label='Frames Hamming Loss', color='red')\n",
    "plt.plot(videos_mean_hm_test, label='Video Hamming Loss', color='green')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(frames_mean_hm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "source": [
    "Multilabel confusion matrix puts TN at (0,0) and TP at (1,1) position thanks @Kenneth Witham for pointing out.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_confusion_matrix(y_test, y_test_pred, labels=range(0,7))\n"
   ]
  },
  {
   "source": [
    "`support`: The number of occurrences of each label in y_true."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_test_pred, target_names=['none', 'furious', 'anger', 'annoyed', 'contempt', 'disgust', 'hatred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(type(y_test[0]))\n",
    "print(type(y_test_pred[0].toarray()))\n",
    "for i in range(len(y_test)):\n",
    "    if metrics.hamming_loss(y_test[i].flatten(), Y_pred_chains[4][i].flatten()) > 0:\n",
    "        print(\"Ground Truth: \", y_test[i], \", Prediction: \", Y_pred_chains[0][i])\n",
    "        print(\"Video data: \", metadata_test.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[800:805])\n",
    "print(metadata_test[800:805])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_test))\n",
    "print(len(metadata_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(input: str):\n",
    "    input = 'persian/' + input +\".mp4\"\n",
    "    return input\n",
    "X_df = pd.read_csv('../new_data/Persian/persian_dataset.csv', index_col=None)\n",
    "X_df['filename'] = X_df['filename'].apply(clean)\n",
    "X_df.to_csv('../new_data/Persian/persian_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}