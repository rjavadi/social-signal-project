{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tslearn.metrics import dtw, soft_dtw\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from sklearn.utils.validation import _check_large_sparse\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, jaccard_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_df(item_lists, unique_items):\n",
    "# Create empty dict\n",
    "    bool_dict = {}\n",
    "    \n",
    "    # Loop through all the tags\n",
    "    for i, item in enumerate(unique_items):\n",
    "        \n",
    "        # Apply boolean mask\n",
    "        bool_dict[item] = item_lists.apply(lambda x: 1 if item in x else 0)\n",
    "            \n",
    "    # Return the results as a dataframe\n",
    "    return pd.DataFrame(bool_dict)\n",
    "\n",
    "def to_1D(series):\n",
    "    return pd.Series([x for _list in series for x in _list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    annoyed  contempt  anger  none  hatred  disgust  furious\n",
       "filename                                                                    \n",
       "persian/vid_1.mp4         1         0      0     0       0        0        0\n",
       "persian/vid_10.mp4        0         1      0     0       0        0        0\n",
       "persian/vid_11.mp4        0         1      0     0       0        0        0\n",
       "persian/vid_12.mp4        0         1      0     0       0        0        0\n",
       "persian/vid_13.mp4        0         0      1     0       0        0        0\n",
       "...                     ...       ...    ...   ...     ...      ...      ...\n",
       "persian/vid_93.mp4        0         0      0     0       1        0        0\n",
       "persian/vid_94.mp4        0         0      0     1       0        0        0\n",
       "persian/vid_95.mp4        0         1      0     0       1        0        0\n",
       "persian/vid_96.mp4        0         1      0     0       0        0        0\n",
       "persian/vid_97.mp4        0         1      0     0       0        0        0\n",
       "\n",
       "[96 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>annoyed</th>\n      <th>contempt</th>\n      <th>anger</th>\n      <th>none</th>\n      <th>hatred</th>\n      <th>disgust</th>\n      <th>furious</th>\n    </tr>\n    <tr>\n      <th>filename</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>persian/vid_1.mp4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>persian/vid_10.mp4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>persian/vid_11.mp4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>persian/vid_12.mp4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>persian/vid_13.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>persian/vid_93.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>persian/vid_94.mp4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>persian/vid_95.mp4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>persian/vid_96.mp4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>persian/vid_97.mp4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>96 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "X_df = pd.read_csv('../new_data/Persian/persian_dataset.csv', index_col=None)\n",
    "Y_df = pd.read_csv('../new_data/Persian/labels.csv', usecols=['filename', 'emotions'], index_col='filename')\n",
    "Y_df[\"emotions\"] = Y_df[\"emotions\"].apply(eval)\n",
    "unique_items = to_1D(Y_df[\"emotions\"]).unique()\n",
    "labels_expanded = boolean_df(Y_df['emotions'], unique_items)\n",
    "labels_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df['none']  = np.NaN\n",
    "X_df['furious']  = np.NaN\n",
    "X_df['anger']  = np.NaN\n",
    "X_df['annoyed']  = np.NaN\n",
    "X_df['contempt']  = np.NaN\n",
    "X_df['disgust']  = np.NaN\n",
    "X_df['hatred']  = np.NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            filename  culture  frame  face_id  timestamp  confidence  success  \\\n",
       "0  persian/vid_1.mp4  persian      1        0      0.000        0.98        1   \n",
       "1  persian/vid_1.mp4  persian      2        0      0.033        0.98        1   \n",
       "2  persian/vid_1.mp4  persian      3        0      0.067        0.98        1   \n",
       "3  persian/vid_1.mp4  persian      4        0      0.100        0.98        1   \n",
       "4  persian/vid_1.mp4  persian      5        0      0.133        0.98        1   \n",
       "\n",
       "   AU01_r  AU02_r  AU04_r  ...  pose_Rz  gaze_angle_x  gaze_angle_y  none  \\\n",
       "0    0.94    0.24    0.43  ...   -0.106         0.408         0.466   NaN   \n",
       "1    0.17    0.00    0.00  ...   -0.113         0.478         0.490   NaN   \n",
       "2    0.10    0.00    0.00  ...   -0.112         0.494         0.471   NaN   \n",
       "3    0.00    0.00    0.00  ...   -0.112         0.540         0.466   NaN   \n",
       "4    0.00    0.00    0.00  ...   -0.115         0.581         0.467   NaN   \n",
       "\n",
       "   furious  anger  annoyed  contempt  disgust  hatred  \n",
       "0      NaN    NaN      NaN       NaN      NaN     NaN  \n",
       "1      NaN    NaN      NaN       NaN      NaN     NaN  \n",
       "2      NaN    NaN      NaN       NaN      NaN     NaN  \n",
       "3      NaN    NaN      NaN       NaN      NaN     NaN  \n",
       "4      NaN    NaN      NaN       NaN      NaN     NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>culture</th>\n      <th>frame</th>\n      <th>face_id</th>\n      <th>timestamp</th>\n      <th>confidence</th>\n      <th>success</th>\n      <th>AU01_r</th>\n      <th>AU02_r</th>\n      <th>AU04_r</th>\n      <th>...</th>\n      <th>pose_Rz</th>\n      <th>gaze_angle_x</th>\n      <th>gaze_angle_y</th>\n      <th>none</th>\n      <th>furious</th>\n      <th>anger</th>\n      <th>annoyed</th>\n      <th>contempt</th>\n      <th>disgust</th>\n      <th>hatred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.94</td>\n      <td>0.24</td>\n      <td>0.43</td>\n      <td>...</td>\n      <td>-0.106</td>\n      <td>0.408</td>\n      <td>0.466</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.033</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.17</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>-0.113</td>\n      <td>0.478</td>\n      <td>0.490</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.067</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.10</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>-0.112</td>\n      <td>0.494</td>\n      <td>0.471</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.100</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>-0.112</td>\n      <td>0.540</td>\n      <td>0.466</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0.133</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>-0.115</td>\n      <td>0.581</td>\n      <td>0.467</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 36 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in X_df.iterrows():\n",
    "    # print(index, row)\n",
    "    filename = X_df.iloc[index]['filename']\n",
    "    # print(labels_expanded.loc[filename]['none':'hatred'].to_list())\n",
    "    X_df.at[index,'none'] = labels_expanded.at[filename,'none']\n",
    "    X_df.at[index,'furious'] = labels_expanded.at[filename,'furious']\n",
    "    X_df.at[index,'anger'] = labels_expanded.at[filename,'anger']\n",
    "    X_df.at[index,'annoyed'] = labels_expanded.at[filename,'annoyed']\n",
    "    X_df.at[index,'contempt'] = labels_expanded.at[filename,'contempt']\n",
    "    X_df.at[index,'disgust'] = labels_expanded.at[filename,'disgust']\n",
    "    X_df.at[index,'hatred'] = labels_expanded.at[filename,'hatred']"
   ]
  },
  {
   "source": [
    "### Min-Max Scaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ablation cols\n",
    "ablation_cols = ['AU01_r','AU02_r','AU04_r','AU05_r','AU06_r','AU07_r','AU09_r', 'AU10_r','AU12_r','AU14_r','AU15_r','AU17_r','AU20_r','AU23_r','AU25_r','AU26_r','AU45_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                filename  culture  frame  face_id  timestamp  confidence  \\\n",
       "0      persian/vid_1.mp4  persian      1        0      0.000        0.98   \n",
       "1      persian/vid_1.mp4  persian      2        0      0.033        0.98   \n",
       "2      persian/vid_1.mp4  persian      3        0      0.067        0.98   \n",
       "3      persian/vid_1.mp4  persian      4        0      0.100        0.98   \n",
       "4      persian/vid_1.mp4  persian      5        0      0.133        0.98   \n",
       "...                  ...      ...    ...      ...        ...         ...   \n",
       "9444  persian/vid_97.mp4  persian     35        0      1.360        0.98   \n",
       "9445  persian/vid_97.mp4  persian     36        0      1.400        0.98   \n",
       "9446  persian/vid_97.mp4  persian     37        0      1.440        0.98   \n",
       "9447  persian/vid_97.mp4  persian     38        0      1.480        0.98   \n",
       "9448  persian/vid_97.mp4  persian     39        0      1.520        0.98   \n",
       "\n",
       "      success  pose_Rx  pose_Ry  pose_Rz  gaze_angle_x  gaze_angle_y  none  \\\n",
       "0           1    0.252   -0.451   -0.106         0.408         0.466   0.0   \n",
       "1           1    0.281   -0.479   -0.113         0.478         0.490   0.0   \n",
       "2           1    0.286   -0.511   -0.112         0.494         0.471   0.0   \n",
       "3           1    0.286   -0.537   -0.112         0.540         0.466   0.0   \n",
       "4           1    0.286   -0.562   -0.115         0.581         0.467   0.0   \n",
       "...       ...      ...      ...      ...           ...           ...   ...   \n",
       "9444        1    0.100   -0.156    0.029         0.132         0.283   0.0   \n",
       "9445        1    0.113   -0.193    0.007         0.186         0.303   0.0   \n",
       "9446        1    0.127   -0.218   -0.013         0.202         0.306   0.0   \n",
       "9447        1    0.139   -0.229   -0.039         0.223         0.303   0.0   \n",
       "9448        1    0.145   -0.241   -0.060         0.196         0.300   0.0   \n",
       "\n",
       "      furious  anger  annoyed  contempt  disgust  hatred  \n",
       "0         0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "1         0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "2         0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "3         0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "4         0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "...       ...    ...      ...       ...      ...     ...  \n",
       "9444      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "9445      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "9446      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "9447      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "9448      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "\n",
       "[9449 rows x 19 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>culture</th>\n      <th>frame</th>\n      <th>face_id</th>\n      <th>timestamp</th>\n      <th>confidence</th>\n      <th>success</th>\n      <th>pose_Rx</th>\n      <th>pose_Ry</th>\n      <th>pose_Rz</th>\n      <th>gaze_angle_x</th>\n      <th>gaze_angle_y</th>\n      <th>none</th>\n      <th>furious</th>\n      <th>anger</th>\n      <th>annoyed</th>\n      <th>contempt</th>\n      <th>disgust</th>\n      <th>hatred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.252</td>\n      <td>-0.451</td>\n      <td>-0.106</td>\n      <td>0.408</td>\n      <td>0.466</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.033</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.281</td>\n      <td>-0.479</td>\n      <td>-0.113</td>\n      <td>0.478</td>\n      <td>0.490</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.067</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.286</td>\n      <td>-0.511</td>\n      <td>-0.112</td>\n      <td>0.494</td>\n      <td>0.471</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.100</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.286</td>\n      <td>-0.537</td>\n      <td>-0.112</td>\n      <td>0.540</td>\n      <td>0.466</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0.133</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.286</td>\n      <td>-0.562</td>\n      <td>-0.115</td>\n      <td>0.581</td>\n      <td>0.467</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9444</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>35</td>\n      <td>0</td>\n      <td>1.360</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.100</td>\n      <td>-0.156</td>\n      <td>0.029</td>\n      <td>0.132</td>\n      <td>0.283</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9445</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>36</td>\n      <td>0</td>\n      <td>1.400</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.113</td>\n      <td>-0.193</td>\n      <td>0.007</td>\n      <td>0.186</td>\n      <td>0.303</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9446</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>37</td>\n      <td>0</td>\n      <td>1.440</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.127</td>\n      <td>-0.218</td>\n      <td>-0.013</td>\n      <td>0.202</td>\n      <td>0.306</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9447</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>38</td>\n      <td>0</td>\n      <td>1.480</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.139</td>\n      <td>-0.229</td>\n      <td>-0.039</td>\n      <td>0.223</td>\n      <td>0.303</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9448</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>39</td>\n      <td>0</td>\n      <td>1.520</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.145</td>\n      <td>-0.241</td>\n      <td>-0.060</td>\n      <td>0.196</td>\n      <td>0.300</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>9449 rows Ã— 19 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "X_df = X_df.drop(columns=ablation_cols)\n",
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = list (\n",
    "    set(X_df.columns.to_list()) - set(['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success', 'none', 'furious', 'anger', 'annoyed', 'contempt', 'disgust', 'hatred'])\n",
    ")\n",
    "scaler = MinMaxScaler()\n",
    "X_df[cols_to_scale] = scaler.fit_transform(X_df[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                filename  culture  frame  face_id  timestamp  confidence  \\\n",
       "9444  persian/vid_97.mp4  persian     35        0       1.36        0.98   \n",
       "9445  persian/vid_97.mp4  persian     36        0       1.40        0.98   \n",
       "9446  persian/vid_97.mp4  persian     37        0       1.44        0.98   \n",
       "9447  persian/vid_97.mp4  persian     38        0       1.48        0.98   \n",
       "9448  persian/vid_97.mp4  persian     39        0       1.52        0.98   \n",
       "\n",
       "      success    AU01_r  AU02_r    AU04_r  ...   pose_Rz  gaze_angle_x  \\\n",
       "9444        1  0.232984     0.0  0.389262  ...  0.523002      0.508136   \n",
       "9445        1  0.157068     0.0  0.310962  ...  0.518160      0.533240   \n",
       "9446        1  0.272251     0.0  0.279642  ...  0.513757      0.540679   \n",
       "9447        1  0.196335     0.0  0.230425  ...  0.508034      0.550442   \n",
       "9448        1  0.191099     0.0  0.129754  ...  0.503412      0.537889   \n",
       "\n",
       "      gaze_angle_y  none  furious  anger  annoyed  contempt  disgust  hatred  \n",
       "9444      0.484157   0.0      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "9445      0.496831   0.0      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "9446      0.498733   0.0      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "9447      0.496831   0.0      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "9448      0.494930   0.0      0.0    0.0      0.0       1.0      0.0     0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>culture</th>\n      <th>frame</th>\n      <th>face_id</th>\n      <th>timestamp</th>\n      <th>confidence</th>\n      <th>success</th>\n      <th>AU01_r</th>\n      <th>AU02_r</th>\n      <th>AU04_r</th>\n      <th>...</th>\n      <th>pose_Rz</th>\n      <th>gaze_angle_x</th>\n      <th>gaze_angle_y</th>\n      <th>none</th>\n      <th>furious</th>\n      <th>anger</th>\n      <th>annoyed</th>\n      <th>contempt</th>\n      <th>disgust</th>\n      <th>hatred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9444</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>35</td>\n      <td>0</td>\n      <td>1.36</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.232984</td>\n      <td>0.0</td>\n      <td>0.389262</td>\n      <td>...</td>\n      <td>0.523002</td>\n      <td>0.508136</td>\n      <td>0.484157</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9445</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>36</td>\n      <td>0</td>\n      <td>1.40</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.157068</td>\n      <td>0.0</td>\n      <td>0.310962</td>\n      <td>...</td>\n      <td>0.518160</td>\n      <td>0.533240</td>\n      <td>0.496831</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9446</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>37</td>\n      <td>0</td>\n      <td>1.44</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.272251</td>\n      <td>0.0</td>\n      <td>0.279642</td>\n      <td>...</td>\n      <td>0.513757</td>\n      <td>0.540679</td>\n      <td>0.498733</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9447</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>38</td>\n      <td>0</td>\n      <td>1.48</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.196335</td>\n      <td>0.0</td>\n      <td>0.230425</td>\n      <td>...</td>\n      <td>0.508034</td>\n      <td>0.550442</td>\n      <td>0.496831</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9448</th>\n      <td>persian/vid_97.mp4</td>\n      <td>persian</td>\n      <td>39</td>\n      <td>0</td>\n      <td>1.52</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.191099</td>\n      <td>0.0</td>\n      <td>0.129754</td>\n      <td>...</td>\n      <td>0.503412</td>\n      <td>0.537889</td>\n      <td>0.494930</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 36 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "X_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting into train and test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            filename  culture  frame  face_id  timestamp  confidence  success  \\\n0  persian/vid_1.mp4  persian      1        0      0.000        0.98        1   \n1  persian/vid_1.mp4  persian      2        0      0.033        0.98        1   \n2  persian/vid_1.mp4  persian      3        0      0.067        0.98        1   \n3  persian/vid_1.mp4  persian      4        0      0.100        0.98        1   \n4  persian/vid_1.mp4  persian      5        0      0.133        0.98        1   \n\n     AU01_r    AU02_r    AU04_r  ...   pose_Rz  gaze_angle_x  gaze_angle_y  \\\n0  0.246073  0.056206  0.096197  ...  0.493286      0.636448      0.600127   \n1  0.044503  0.000000  0.000000  ...  0.491746      0.668991      0.615336   \n2  0.026178  0.000000  0.000000  ...  0.491966      0.676430      0.603295   \n3  0.000000  0.000000  0.000000  ...  0.491966      0.697815      0.600127   \n4  0.000000  0.000000  0.000000  ...  0.491305      0.716876      0.600760   \n\n   none  furious  anger  annoyed  contempt  disgust  hatred  \n0   0.0      0.0    0.0      1.0       0.0      0.0     0.0  \n1   0.0      0.0    0.0      1.0       0.0      0.0     0.0  \n2   0.0      0.0    0.0      1.0       0.0      0.0     0.0  \n3   0.0      0.0    0.0      1.0       0.0      0.0     0.0  \n4   0.0      0.0    0.0      1.0       0.0      0.0     0.0  \n\n[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "metadata_cols = ['frame', 'face_id', 'culture', 'filename', 'timestamp']\n",
    "print(X_df.head())\n",
    "videos = X_df['filename'].unique()\n",
    "test_videos = pd.Series(videos).sample(frac=0.20)\n",
    "train_videos = np.array(list(set(videos) - set(test_videos)))\n",
    "test_df = X_df[X_df['filename'].isin(test_videos)]\n",
    "metadata_test = test_df[metadata_cols]\n",
    "y_test = test_df[['none', 'furious', 'anger', 'annoyed', 'contempt', 'disgust', 'hatred']].values\n",
    "X_test = test_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success']).values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 1., 1., 0.],\n",
       "       [0., 0., 1., 0., 1., 1., 0.],\n",
       "       [0., 0., 1., 0., 1., 1., 0.],\n",
       "       [0., 0., 1., 0., 1., 1., 0.],\n",
       "       [0., 0., 1., 0., 1., 1., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "y_test[800:805,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      frame  face_id  culture            filename  timestamp\n",
       "3720    112        0  persian  persian/vid_43.mp4      4.427\n",
       "3721    113        0  persian  persian/vid_43.mp4      4.467\n",
       "3722    114        0  persian  persian/vid_43.mp4      4.507\n",
       "3723    115        0  persian  persian/vid_43.mp4      4.547\n",
       "3724    116        0  persian  persian/vid_43.mp4      4.587"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frame</th>\n      <th>face_id</th>\n      <th>culture</th>\n      <th>filename</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3720</th>\n      <td>112</td>\n      <td>0</td>\n      <td>persian</td>\n      <td>persian/vid_43.mp4</td>\n      <td>4.427</td>\n    </tr>\n    <tr>\n      <th>3721</th>\n      <td>113</td>\n      <td>0</td>\n      <td>persian</td>\n      <td>persian/vid_43.mp4</td>\n      <td>4.467</td>\n    </tr>\n    <tr>\n      <th>3722</th>\n      <td>114</td>\n      <td>0</td>\n      <td>persian</td>\n      <td>persian/vid_43.mp4</td>\n      <td>4.507</td>\n    </tr>\n    <tr>\n      <th>3723</th>\n      <td>115</td>\n      <td>0</td>\n      <td>persian</td>\n      <td>persian/vid_43.mp4</td>\n      <td>4.547</td>\n    </tr>\n    <tr>\n      <th>3724</th>\n      <td>116</td>\n      <td>0</td>\n      <td>persian</td>\n      <td>persian/vid_43.mp4</td>\n      <td>4.587</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "metadata_test.iloc[800:805]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Cross-validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['persian/vid_1.mp4' 'persian/vid_10.mp4' 'persian/vid_12.mp4'\n",
      " 'persian/vid_13.mp4' 'persian/vid_14.mp4' 'persian/vid_15.mp4'\n",
      " 'persian/vid_16.mp4' 'persian/vid_17.mp4' 'persian/vid_18.mp4'\n",
      " 'persian/vid_2.mp4' 'persian/vid_20.mp4' 'persian/vid_21.mp4'\n",
      " 'persian/vid_22.mp4' 'persian/vid_23.mp4' 'persian/vid_24.mp4'\n",
      " 'persian/vid_25.mp4' 'persian/vid_26.mp4' 'persian/vid_28.mp4'\n",
      " 'persian/vid_29.mp4' 'persian/vid_3.mp4' 'persian/vid_30.mp4'\n",
      " 'persian/vid_31.mp4' 'persian/vid_32.mp4' 'persian/vid_35.mp4'\n",
      " 'persian/vid_36.mp4' 'persian/vid_37.mp4' 'persian/vid_38.mp4'\n",
      " 'persian/vid_4.mp4' 'persian/vid_42.mp4' 'persian/vid_43.mp4'\n",
      " 'persian/vid_44.mp4' 'persian/vid_45.mp4' 'persian/vid_49.mp4'\n",
      " 'persian/vid_5.mp4' 'persian/vid_50.mp4' 'persian/vid_52.mp4'\n",
      " 'persian/vid_53.mp4' 'persian/vid_55.mp4' 'persian/vid_56.mp4'\n",
      " 'persian/vid_57.mp4' 'persian/vid_59.mp4' 'persian/vid_6.mp4'\n",
      " 'persian/vid_60.mp4' 'persian/vid_63.mp4' 'persian/vid_64.mp4'\n",
      " 'persian/vid_65.mp4' 'persian/vid_66.mp4' 'persian/vid_68.mp4'\n",
      " 'persian/vid_69.mp4' 'persian/vid_7.mp4' 'persian/vid_70.mp4'\n",
      " 'persian/vid_71.mp4' 'persian/vid_72.mp4' 'persian/vid_73.mp4'\n",
      " 'persian/vid_74.mp4' 'persian/vid_75.mp4' 'persian/vid_77.mp4'\n",
      " 'persian/vid_78.mp4' 'persian/vid_79.mp4' 'persian/vid_8.mp4']\n",
      "['persian/vid_11.mp4' 'persian/vid_19.mp4' 'persian/vid_27.mp4'\n",
      " 'persian/vid_33.mp4' 'persian/vid_34.mp4' 'persian/vid_40.mp4'\n",
      " 'persian/vid_41.mp4' 'persian/vid_46.mp4' 'persian/vid_48.mp4'\n",
      " 'persian/vid_51.mp4' 'persian/vid_54.mp4' 'persian/vid_58.mp4'\n",
      " 'persian/vid_61.mp4' 'persian/vid_62.mp4' 'persian/vid_67.mp4'\n",
      " 'persian/vid_76.mp4']\n",
      "1-th split: train: 60, test: 16\n",
      "Training+validation data size:  6345\n",
      "Training data size:  4758\n",
      "Validation data size:  1587\n",
      "Validation score in model 0: 1\n",
      "Validation score in model 1: 1\n",
      "Validation score in model 2: 1\n",
      "Validation score in model 3: 1\n",
      "Validation score in model 4: 1\n",
      "Validation score in model 5: 1\n",
      "Validation score in model 6: 1\n",
      "Validation Jaccard Score:\n",
      "  [1.0, 1.0, 1.0, 1.0, 0.998792270531401, 1.0, 1.0]\n",
      "Test Jaccard Score: \n",
      "  [0.9869162640901772, 0.9869162640901772, 0.9869162640901772, 0.9869162640901772, 0.9869162640901772, 0.9869162640901772, 0.9869162640901772]\n",
      "['persian/vid_1.mp4' 'persian/vid_10.mp4' 'persian/vid_11.mp4'\n",
      " 'persian/vid_12.mp4' 'persian/vid_13.mp4' 'persian/vid_14.mp4'\n",
      " 'persian/vid_15.mp4' 'persian/vid_16.mp4' 'persian/vid_17.mp4'\n",
      " 'persian/vid_18.mp4' 'persian/vid_19.mp4' 'persian/vid_2.mp4'\n",
      " 'persian/vid_20.mp4' 'persian/vid_21.mp4' 'persian/vid_22.mp4'\n",
      " 'persian/vid_24.mp4' 'persian/vid_25.mp4' 'persian/vid_26.mp4'\n",
      " 'persian/vid_27.mp4' 'persian/vid_28.mp4' 'persian/vid_3.mp4'\n",
      " 'persian/vid_30.mp4' 'persian/vid_31.mp4' 'persian/vid_32.mp4'\n",
      " 'persian/vid_33.mp4' 'persian/vid_34.mp4' 'persian/vid_35.mp4'\n",
      " 'persian/vid_36.mp4' 'persian/vid_37.mp4' 'persian/vid_4.mp4'\n",
      " 'persian/vid_40.mp4' 'persian/vid_41.mp4' 'persian/vid_44.mp4'\n",
      " 'persian/vid_46.mp4' 'persian/vid_48.mp4' 'persian/vid_49.mp4'\n",
      " 'persian/vid_5.mp4' 'persian/vid_51.mp4' 'persian/vid_52.mp4'\n",
      " 'persian/vid_53.mp4' 'persian/vid_54.mp4' 'persian/vid_55.mp4'\n",
      " 'persian/vid_56.mp4' 'persian/vid_57.mp4' 'persian/vid_58.mp4'\n",
      " 'persian/vid_59.mp4' 'persian/vid_60.mp4' 'persian/vid_61.mp4'\n",
      " 'persian/vid_62.mp4' 'persian/vid_64.mp4' 'persian/vid_67.mp4'\n",
      " 'persian/vid_68.mp4' 'persian/vid_69.mp4' 'persian/vid_7.mp4'\n",
      " 'persian/vid_70.mp4' 'persian/vid_73.mp4' 'persian/vid_75.mp4'\n",
      " 'persian/vid_76.mp4' 'persian/vid_77.mp4' 'persian/vid_78.mp4'\n",
      " 'persian/vid_8.mp4']\n",
      "['persian/vid_23.mp4' 'persian/vid_29.mp4' 'persian/vid_38.mp4'\n",
      " 'persian/vid_42.mp4' 'persian/vid_43.mp4' 'persian/vid_45.mp4'\n",
      " 'persian/vid_50.mp4' 'persian/vid_6.mp4' 'persian/vid_63.mp4'\n",
      " 'persian/vid_65.mp4' 'persian/vid_66.mp4' 'persian/vid_71.mp4'\n",
      " 'persian/vid_72.mp4' 'persian/vid_74.mp4' 'persian/vid_79.mp4']\n",
      "2-th split: train: 61, test: 15\n",
      "Training+validation data size:  5940\n",
      "Training data size:  4455\n",
      "Validation data size:  1485\n",
      "Validation score in model 0: 1\n",
      "Validation score in model 1: 1\n",
      "Validation score in model 2: 1\n",
      "Validation score in model 3: 1\n",
      "Validation score in model 4: 1\n",
      "Validation score in model 5: 1\n",
      "Validation score in model 6: 1\n",
      "Validation Jaccard Score:\n",
      "  [0.9869162640901772, 0.9869162640901772, 0.9869162640901772, 0.9869162640901772, 0.9869162640901772, 0.9869162640901772, 0.9869162640901772]\n",
      "Test Jaccard Score: \n",
      "  [0.964975845410628, 0.964975845410628, 0.964975845410628, 0.964975845410628, 0.964975845410628, 0.964975845410628, 0.964975845410628]\n",
      "['persian/vid_10.mp4' 'persian/vid_11.mp4' 'persian/vid_13.mp4'\n",
      " 'persian/vid_14.mp4' 'persian/vid_15.mp4' 'persian/vid_18.mp4'\n",
      " 'persian/vid_19.mp4' 'persian/vid_2.mp4' 'persian/vid_20.mp4'\n",
      " 'persian/vid_22.mp4' 'persian/vid_23.mp4' 'persian/vid_24.mp4'\n",
      " 'persian/vid_26.mp4' 'persian/vid_27.mp4' 'persian/vid_28.mp4'\n",
      " 'persian/vid_29.mp4' 'persian/vid_3.mp4' 'persian/vid_30.mp4'\n",
      " 'persian/vid_32.mp4' 'persian/vid_33.mp4' 'persian/vid_34.mp4'\n",
      " 'persian/vid_35.mp4' 'persian/vid_36.mp4' 'persian/vid_37.mp4'\n",
      " 'persian/vid_38.mp4' 'persian/vid_4.mp4' 'persian/vid_40.mp4'\n",
      " 'persian/vid_41.mp4' 'persian/vid_42.mp4' 'persian/vid_43.mp4'\n",
      " 'persian/vid_44.mp4' 'persian/vid_45.mp4' 'persian/vid_46.mp4'\n",
      " 'persian/vid_48.mp4' 'persian/vid_49.mp4' 'persian/vid_5.mp4'\n",
      " 'persian/vid_50.mp4' 'persian/vid_51.mp4' 'persian/vid_54.mp4'\n",
      " 'persian/vid_56.mp4' 'persian/vid_57.mp4' 'persian/vid_58.mp4'\n",
      " 'persian/vid_59.mp4' 'persian/vid_6.mp4' 'persian/vid_61.mp4'\n",
      " 'persian/vid_62.mp4' 'persian/vid_63.mp4' 'persian/vid_65.mp4'\n",
      " 'persian/vid_66.mp4' 'persian/vid_67.mp4' 'persian/vid_68.mp4'\n",
      " 'persian/vid_7.mp4' 'persian/vid_70.mp4' 'persian/vid_71.mp4'\n",
      " 'persian/vid_72.mp4' 'persian/vid_74.mp4' 'persian/vid_75.mp4'\n",
      " 'persian/vid_76.mp4' 'persian/vid_77.mp4' 'persian/vid_79.mp4'\n",
      " 'persian/vid_8.mp4']\n",
      "['persian/vid_1.mp4' 'persian/vid_12.mp4' 'persian/vid_16.mp4'\n",
      " 'persian/vid_17.mp4' 'persian/vid_21.mp4' 'persian/vid_25.mp4'\n",
      " 'persian/vid_31.mp4' 'persian/vid_52.mp4' 'persian/vid_53.mp4'\n",
      " 'persian/vid_55.mp4' 'persian/vid_60.mp4' 'persian/vid_64.mp4'\n",
      " 'persian/vid_69.mp4' 'persian/vid_73.mp4' 'persian/vid_78.mp4']\n",
      "3-th split: train: 61, test: 15\n",
      "Training+validation data size:  6055\n",
      "Training data size:  4541\n",
      "Validation data size:  1514\n",
      "Validation score in model 0: 1\n",
      "Validation score in model 1: 1\n",
      "Validation score in model 2: 1\n",
      "Validation score in model 3: 1\n",
      "Validation score in model 4: 1\n",
      "Validation score in model 5: 1\n",
      "Validation score in model 6: 1\n",
      "Validation Jaccard Score:\n",
      "  [0.964975845410628, 0.964975845410628, 0.964975845410628, 0.964975845410628, 0.964975845410628, 0.964975845410628, 0.964975845410628]\n",
      "Test Jaccard Score: \n",
      "  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "['persian/vid_1.mp4' 'persian/vid_10.mp4' 'persian/vid_11.mp4'\n",
      " 'persian/vid_12.mp4' 'persian/vid_14.mp4' 'persian/vid_15.mp4'\n",
      " 'persian/vid_16.mp4' 'persian/vid_17.mp4' 'persian/vid_18.mp4'\n",
      " 'persian/vid_19.mp4' 'persian/vid_20.mp4' 'persian/vid_21.mp4'\n",
      " 'persian/vid_23.mp4' 'persian/vid_24.mp4' 'persian/vid_25.mp4'\n",
      " 'persian/vid_26.mp4' 'persian/vid_27.mp4' 'persian/vid_28.mp4'\n",
      " 'persian/vid_29.mp4' 'persian/vid_31.mp4' 'persian/vid_32.mp4'\n",
      " 'persian/vid_33.mp4' 'persian/vid_34.mp4' 'persian/vid_38.mp4'\n",
      " 'persian/vid_40.mp4' 'persian/vid_41.mp4' 'persian/vid_42.mp4'\n",
      " 'persian/vid_43.mp4' 'persian/vid_44.mp4' 'persian/vid_45.mp4'\n",
      " 'persian/vid_46.mp4' 'persian/vid_48.mp4' 'persian/vid_50.mp4'\n",
      " 'persian/vid_51.mp4' 'persian/vid_52.mp4' 'persian/vid_53.mp4'\n",
      " 'persian/vid_54.mp4' 'persian/vid_55.mp4' 'persian/vid_57.mp4'\n",
      " 'persian/vid_58.mp4' 'persian/vid_6.mp4' 'persian/vid_60.mp4'\n",
      " 'persian/vid_61.mp4' 'persian/vid_62.mp4' 'persian/vid_63.mp4'\n",
      " 'persian/vid_64.mp4' 'persian/vid_65.mp4' 'persian/vid_66.mp4'\n",
      " 'persian/vid_67.mp4' 'persian/vid_68.mp4' 'persian/vid_69.mp4'\n",
      " 'persian/vid_7.mp4' 'persian/vid_71.mp4' 'persian/vid_72.mp4'\n",
      " 'persian/vid_73.mp4' 'persian/vid_74.mp4' 'persian/vid_76.mp4'\n",
      " 'persian/vid_77.mp4' 'persian/vid_78.mp4' 'persian/vid_79.mp4'\n",
      " 'persian/vid_8.mp4']\n",
      "['persian/vid_13.mp4' 'persian/vid_2.mp4' 'persian/vid_22.mp4'\n",
      " 'persian/vid_3.mp4' 'persian/vid_30.mp4' 'persian/vid_35.mp4'\n",
      " 'persian/vid_36.mp4' 'persian/vid_37.mp4' 'persian/vid_4.mp4'\n",
      " 'persian/vid_49.mp4' 'persian/vid_5.mp4' 'persian/vid_56.mp4'\n",
      " 'persian/vid_59.mp4' 'persian/vid_70.mp4' 'persian/vid_75.mp4']\n",
      "4-th split: train: 61, test: 15\n",
      "Training+validation data size:  6575\n",
      "Training data size:  4931\n",
      "Validation data size:  1644\n",
      "Validation score in model 0: 1\n",
      "Validation score in model 1: 1\n",
      "Validation score in model 2: 1\n",
      "Validation score in model 3: 1\n",
      "Validation score in model 4: 1\n",
      "Validation score in model 5: 1\n",
      "Validation score in model 6: 1\n",
      "Validation Jaccard Score:\n",
      "  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Test Jaccard Score: \n",
      "  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "['persian/vid_1.mp4' 'persian/vid_11.mp4' 'persian/vid_12.mp4'\n",
      " 'persian/vid_13.mp4' 'persian/vid_16.mp4' 'persian/vid_17.mp4'\n",
      " 'persian/vid_19.mp4' 'persian/vid_2.mp4' 'persian/vid_21.mp4'\n",
      " 'persian/vid_22.mp4' 'persian/vid_23.mp4' 'persian/vid_25.mp4'\n",
      " 'persian/vid_27.mp4' 'persian/vid_29.mp4' 'persian/vid_3.mp4'\n",
      " 'persian/vid_30.mp4' 'persian/vid_31.mp4' 'persian/vid_33.mp4'\n",
      " 'persian/vid_34.mp4' 'persian/vid_35.mp4' 'persian/vid_36.mp4'\n",
      " 'persian/vid_37.mp4' 'persian/vid_38.mp4' 'persian/vid_4.mp4'\n",
      " 'persian/vid_40.mp4' 'persian/vid_41.mp4' 'persian/vid_42.mp4'\n",
      " 'persian/vid_43.mp4' 'persian/vid_45.mp4' 'persian/vid_46.mp4'\n",
      " 'persian/vid_48.mp4' 'persian/vid_49.mp4' 'persian/vid_5.mp4'\n",
      " 'persian/vid_50.mp4' 'persian/vid_51.mp4' 'persian/vid_52.mp4'\n",
      " 'persian/vid_53.mp4' 'persian/vid_54.mp4' 'persian/vid_55.mp4'\n",
      " 'persian/vid_56.mp4' 'persian/vid_58.mp4' 'persian/vid_59.mp4'\n",
      " 'persian/vid_6.mp4' 'persian/vid_60.mp4' 'persian/vid_61.mp4'\n",
      " 'persian/vid_62.mp4' 'persian/vid_63.mp4' 'persian/vid_64.mp4'\n",
      " 'persian/vid_65.mp4' 'persian/vid_66.mp4' 'persian/vid_67.mp4'\n",
      " 'persian/vid_69.mp4' 'persian/vid_70.mp4' 'persian/vid_71.mp4'\n",
      " 'persian/vid_72.mp4' 'persian/vid_73.mp4' 'persian/vid_74.mp4'\n",
      " 'persian/vid_75.mp4' 'persian/vid_76.mp4' 'persian/vid_78.mp4'\n",
      " 'persian/vid_79.mp4']\n",
      "['persian/vid_10.mp4' 'persian/vid_14.mp4' 'persian/vid_15.mp4'\n",
      " 'persian/vid_18.mp4' 'persian/vid_20.mp4' 'persian/vid_24.mp4'\n",
      " 'persian/vid_26.mp4' 'persian/vid_28.mp4' 'persian/vid_32.mp4'\n",
      " 'persian/vid_44.mp4' 'persian/vid_57.mp4' 'persian/vid_68.mp4'\n",
      " 'persian/vid_7.mp4' 'persian/vid_77.mp4' 'persian/vid_8.mp4']\n",
      "5-th split: train: 61, test: 15\n",
      "Training+validation data size:  5985\n",
      "Training data size:  4488\n",
      "Validation data size:  1497\n",
      "Validation score in model 0: 1\n",
      "Validation score in model 1: 1\n",
      "Validation score in model 2: 1\n",
      "Validation score in model 3: 1\n",
      "Validation score in model 4: 1\n",
      "Validation score in model 5: 1\n",
      "Validation score in model 6: 1\n",
      "Validation Jaccard Score:\n",
      "  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Test Jaccard Score: \n",
      "  [0.9571256038647343, 0.9571256038647343, 0.9571256038647343, 0.9571256038647343, 0.9571256038647343, 0.9571256038647343, 0.9571256038647343]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "kfold = KFold(5, True, 1)\n",
    "\n",
    "\n",
    "splits = kfold.split(train_videos)\n",
    "for (i, (train, test)) in enumerate(splits):\n",
    "    print(videos[train])\n",
    "    print(videos[test])\n",
    "    print('%d-th split: train: %d, test: %d' % (i+1, len(videos[train]), len(videos[test])))\n",
    "    train_df = X_df[X_df['filename'].isin(videos[train])]\n",
    "    train_metadata = train_df[metadata_cols]\n",
    "    print('Training+validation data size: ', train_df.shape[0])\n",
    "    y = train_df[['none', 'furious', 'anger', 'annoyed', 'contempt', 'disgust', 'hatred']].values\n",
    "    X = train_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success']).values\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "    print('Training data size: ', X_train.shape[0])\n",
    "    print('Validation data size: ', X_valid.shape[0])\n",
    "    base_knn =  KNeighborsClassifier(n_neighbors=25,)\n",
    "    base_lr = LogisticRegression()\n",
    "    base_rf = RandomForestClassifier()\n",
    "    chains = [ClassifierChain(base_knn, order='random', random_state=i)\n",
    "            for i in range(7)]\n",
    "    for j, model in enumerate(chains):\n",
    "        model.fit(X_train, y_train)\n",
    "        valid_pred = model.predict(X_valid)\n",
    "        val_score =jaccard_score(y_valid, valid_pred, average='samples')\n",
    "        print('Validation score in model %d: %d' % (j, val_score) )\n",
    "        \n",
    "    # predict on validation data\n",
    "    # valid_pred_chains = np.array([chain.predict(X_valid) for chain in\n",
    "    #                         chains])\n",
    "    # chain_accuracy_scores = [jaccard_score(y_valid, valid_pred_chain >= .5,\n",
    "    #                                 average='samples')\n",
    "    #                 for valid_pred_chain in valid_pred_chains]\n",
    "    \n",
    "    print(\"Validation Jaccard Score:\\n \", chain_accuracy_scores)\n",
    "    # test on test data\n",
    "    Y_pred_chains = np.array([chain.predict(X_test) for chain in\n",
    "                            chains])\n",
    "    chain_accuracy_scores = [jaccard_score(y_test, Y_pred_chain >= .5,\n",
    "                                    average='samples')\n",
    "                    for Y_pred_chain in Y_pred_chains]\n",
    "\n",
    "    print(\"Test Jaccard Score: \\n \", chain_accuracy_scores)\n",
    "\n",
    "\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1-th split: train: 60, test: 16\n",
      "Training+validation data size:  6345\n",
      "Training data size:  4758\n",
      "Validation data size:  1587\n",
      "Validation Hamming Loss:\n",
      "  0.0\n",
      "Test Hamming Loss:\n",
      "  0.005607315389924086\n",
      "2-th split: train: 61, test: 15\n",
      "Training+validation data size:  5940\n",
      "Training data size:  4455\n",
      "Validation data size:  1485\n",
      "Validation Hamming Loss:\n",
      "  0.0\n",
      "Test Hamming Loss:\n",
      "  0.015010351966873706\n",
      "3-th split: train: 61, test: 15\n",
      "Training+validation data size:  6055\n",
      "Training data size:  4541\n",
      "Validation data size:  1514\n",
      "Validation Hamming Loss:\n",
      "  0.0\n",
      "Test Hamming Loss:\n",
      "  0.0\n",
      "4-th split: train: 61, test: 15\n",
      "Training+validation data size:  6575\n",
      "Training data size:  4931\n",
      "Validation data size:  1644\n",
      "Validation Hamming Loss:\n",
      "  0.0\n",
      "Test Hamming Loss:\n",
      "  0.0\n",
      "5-th split: train: 61, test: 15\n",
      "Training+validation data size:  5985\n",
      "Training data size:  4488\n",
      "Validation data size:  1497\n",
      "Validation Hamming Loss:\n",
      "  0.0\n",
      "Test Hamming Loss:\n",
      "  0.015010351966873706\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN, MLTSVM\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "## MLTSVM is not compatible with later versions of numpy\n",
    "\n",
    "kfold = KFold(5, True, 1)\n",
    "\n",
    "\n",
    "splits = kfold.split(train_videos)\n",
    "for (i, (train, test)) in enumerate(splits):\n",
    "    # print(videos[train])\n",
    "    # print(videos[test])\n",
    "    print('%d-th split: train: %d, test: %d' % (i+1, len(videos[train]), len(videos[test])))\n",
    "    train_df = X_df[X_df['filename'].isin(videos[train])]\n",
    "    train_metadata = train_df[metadata_cols]\n",
    "    print('Training+validation data size: ', train_df.shape[0])\n",
    "    y = train_df[['none', 'furious', 'anger', 'annoyed', 'contempt', 'disgust', 'hatred']].values\n",
    "    X = train_df.drop(columns = ['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success']).values\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "    print('Training data size: ', X_train.shape[0])\n",
    "    print('Validation data size: ', X_valid.shape[0])\n",
    "    classifier = MLkNN(k=8)\n",
    "    # classifier = MLTSVM(c_k = 2**-1)\n",
    "    prediction = classifier.fit(X_train, y_train).predict(X_valid)\n",
    "    print(\"Validation Hamming Loss:\\n \", metrics.hamming_loss(y_valid, prediction))\n",
    "    y_test_pred = classifier.predict(X_test)\n",
    "    print(\"Test Hamming Loss:\\n \", metrics.hamming_loss(y_test, y_test_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            filename  culture  frame  face_id  timestamp  confidence  success  \\\n",
       "0  persian/vid_1.mp4  persian      1        0      0.000        0.98        1   \n",
       "1  persian/vid_1.mp4  persian      2        0      0.033        0.98        1   \n",
       "2  persian/vid_1.mp4  persian      3        0      0.067        0.98        1   \n",
       "3  persian/vid_1.mp4  persian      4        0      0.100        0.98        1   \n",
       "4  persian/vid_1.mp4  persian      5        0      0.133        0.98        1   \n",
       "\n",
       "   AU10_r  AU12_r  AU14_r  ...  pose_Rz  gaze_angle_x  gaze_angle_y  none  \\\n",
       "0    0.98    0.66     0.0  ...   -0.106         0.408         0.466   0.0   \n",
       "1    1.58    0.62     0.0  ...   -0.113         0.478         0.490   0.0   \n",
       "2    1.55    0.58     0.0  ...   -0.112         0.494         0.471   0.0   \n",
       "3    1.30    0.47     0.0  ...   -0.112         0.540         0.466   0.0   \n",
       "4    1.37    0.75     0.0  ...   -0.115         0.581         0.467   0.0   \n",
       "\n",
       "   furious  anger  annoyed  contempt  disgust  hatred  \n",
       "0      0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "1      0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "2      0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "3      0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "4      0.0    0.0      1.0       0.0      0.0     0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>culture</th>\n      <th>frame</th>\n      <th>face_id</th>\n      <th>timestamp</th>\n      <th>confidence</th>\n      <th>success</th>\n      <th>AU10_r</th>\n      <th>AU12_r</th>\n      <th>AU14_r</th>\n      <th>...</th>\n      <th>pose_Rz</th>\n      <th>gaze_angle_x</th>\n      <th>gaze_angle_y</th>\n      <th>none</th>\n      <th>furious</th>\n      <th>anger</th>\n      <th>annoyed</th>\n      <th>contempt</th>\n      <th>disgust</th>\n      <th>hatred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>0.98</td>\n      <td>0.66</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.106</td>\n      <td>0.408</td>\n      <td>0.466</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.033</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>1.58</td>\n      <td>0.62</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.113</td>\n      <td>0.478</td>\n      <td>0.490</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.067</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>1.55</td>\n      <td>0.58</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.112</td>\n      <td>0.494</td>\n      <td>0.471</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.100</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>1.30</td>\n      <td>0.47</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.112</td>\n      <td>0.540</td>\n      <td>0.466</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>persian/vid_1.mp4</td>\n      <td>persian</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0.133</td>\n      <td>0.98</td>\n      <td>1</td>\n      <td>1.37</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.115</td>\n      <td>0.581</td>\n      <td>0.467</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 29 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[1474,    0],\n",
       "        [   0,  182]],\n",
       "\n",
       "       [[1296,    0],\n",
       "        [   0,  360]],\n",
       "\n",
       "       [[1223,    0],\n",
       "        [   0,  433]],\n",
       "\n",
       "       [[1396,    0],\n",
       "        [   0,  260]],\n",
       "\n",
       "       [[1092,    0],\n",
       "        [  21,  543]],\n",
       "\n",
       "       [[1412,    0],\n",
       "        [   0,  244]],\n",
       "\n",
       "       [[1348,    0],\n",
       "        [ 121,  187]]])"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "multilabel_confusion_matrix(y_test, Y_pred_chains[1], labels=range(0,7))\n",
    "Multilabel confusion matrix puts TN at (0,0) and TP at (1,1) position thanks @Kenneth Witham for pointing out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n        none       1.00      1.00      1.00       182\n     furious       1.00      1.00      1.00       360\n       anger       1.00      1.00      1.00       433\n     annoyed       1.00      1.00      1.00       260\n    contempt       1.00      0.96      0.98       564\n     disgust       1.00      1.00      1.00       244\n      hatred       1.00      0.61      0.76       308\n\n   micro avg       1.00      0.94      0.97      2351\n   macro avg       1.00      0.94      0.96      2351\nweighted avg       1.00      0.94      0.96      2351\n samples avg       1.00      0.96      0.97      2351\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, Y_pred_chains[0], target_names=['none', 'furious', 'anger', 'annoyed', 'contempt', 'disgust', 'hatred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 1. 0. 1. 1. 0.]\n [0. 0. 1. 0. 1. 1. 0.]\n [0. 0. 1. 0. 1. 1. 0.]\n [0. 0. 1. 0. 1. 1. 0.]\n [0. 0. 1. 0. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred_chains[1][800:805])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 1. 0. 1. 1. 0.]\n [0. 0. 1. 0. 1. 1. 0.]\n [0. 0. 1. 0. 1. 1. 0.]\n [0. 0. 1. 0. 1. 1. 0.]\n [0. 0. 1. 0. 1. 1. 0.]]\n      frame  face_id  culture            filename  timestamp\n3720    112        0  persian  persian/vid_43.mp4      4.427\n3721    113        0  persian  persian/vid_43.mp4      4.467\n3722    114        0  persian  persian/vid_43.mp4      4.507\n3723    115        0  persian  persian/vid_43.mp4      4.547\n3724    116        0  persian  persian/vid_43.mp4      4.587\n"
     ]
    }
   ],
   "source": [
    "print(y_test[800:805])\n",
    "print(metadata_test[800:805])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1656\n1656\n"
     ]
    }
   ],
   "source": [
    "print(len(y_test))\n",
    "print(len(metadata_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Break data into chunks of 50 frames or less"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped = X_df.groupby(by=['filename', 'face_id'])\n",
    "## Separating test data\n",
    "test_ts_list = list()\n",
    "test_metadata = list()\n",
    "# X_list is video/face frames, divided into 50 frames chunks\n",
    "X_list = []\n",
    "Y_list = []\n",
    "metadata = []\n",
    "frame_limit = 50\n",
    "for key in grouped.groups:\n",
    "    X_group = grouped.get_group(key)\n",
    "    # X_group = X_group.drop(['frame', 'face_id', 'culture', 'filename', 'emotion', 'confidence','success'], axis=1)\n",
    "    if len(X_group) >= frame_limit:\n",
    "        splitted_group = np.array_split(X_group, math.ceil(len(X_group) / frame_limit))\n",
    "        for g in splitted_group:\n",
    "            X_list.append(g.drop(['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success'], axis=1).to_numpy())\n",
    "            metadata.append({'filename': g.loc[g.index[0], 'filename'], 'face_id':g.loc[g.index[0], 'face_id']})\n",
    "            Y_list.append(Y_df.loc[g.loc[g.index[0], 'filename']].to_list())\n",
    "    else:\n",
    "        X_list.append(X_group.drop(['frame', 'face_id', 'culture', 'filename', 'timestamp', 'confidence','success'], axis=1).to_numpy())\n",
    "        metadata.append({'filename': X_group.loc[X_group.index[0], 'filename'],  'face_id':X_group.loc[X_group.index[0], 'face_id']})\n",
    "        Y_list.append(Y_df.loc[g.loc[g.index[0], 'filename']].to_list())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ts = to_time_series_dataset(X_list)\n",
    "\n",
    "n_series = len(X_ts)\n",
    "distance_matrix = np.zeros(shape=(n_series, n_series))\n",
    "\n",
    "# Build distance matrix\n",
    "for i in range(n_series):\n",
    "    for j in range(n_series):\n",
    "        x = X_ts[i]\n",
    "        y = X_ts[j]\n",
    "        if i != j:\n",
    "            dist = soft_dtw(x, y)\n",
    "            distance_matrix[i, j] = dist"
   ]
  },
  {
   "source": [
    "https://scikit-learn.org/stable/modules/multiclass.html#classifierchain\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_ts, Y_list, test_size=.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "base_knn =  KNeighborsClassifier(n_neighbors=5)\n",
    "chains = [ClassifierChain(base_knn, order='random', random_state=i)\n",
    "          for i in range(7)]\n",
    "for model in chains:\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_chains = np.array([chain.predict(X_test) for chain in\n",
    "                          chains])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(input: str):\n",
    "    input = 'persian/' + input +\".mp4\"\n",
    "    return input\n",
    "X_df = pd.read_csv('../new_data/Persian/persian_dataset.csv', index_col=None)\n",
    "X_df['filename'] = X_df['filename'].apply(clean)\n",
    "X_df.to_csv('../new_data/Persian/persian_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}